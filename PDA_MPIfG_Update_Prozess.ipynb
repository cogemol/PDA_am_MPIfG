{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Buchhandelsdaten in Vufind als Grundlage für PDA (Patron Driven Aquisition) am MPIfG / Version 2: Updates laden statt Vollimport\n",
    "\n",
    "Einbindung von freundlicherweise von Schweitzer Fachinformation zur Verfügung gestellten Daten.   \n",
    "(Auswahl über passend konfigurierte Neuerscheinungsabfragen in unserem Kundenprofil).   \n",
    "\n",
    "#### Gründe für die Umstellung auf Updates: Durch Einspielen der Daten in Vufind ergibt sich eine zeitliche Diskrepanz, in der Titel bereits in Aleph gelöscht sind, aber in Vufind noch bestellbar. Zudem werden die Aleph-IDs hochgezähl, denn bei jedem Einspielen werden neue Nummern vergeben. Durch die Updates bleiben die Titel weiterhin verfügbar und das Hochzählen der IDs hält sich im Rahmen. Das Skript beschleunigt sich durch Reduzierung der Abfragen am Server.\n",
    "*Kleiner Nachteil: der manuelle Aufwand vergrößert sich. Mehrere Dateien müssen in Aleph eingespielt und verarbeitet werden, aber hält sich nach wie vor im vertretbaren Rahmen.*\n",
    "\n",
    "Das Jupyter Notebook arbeitet mit Python 3.8.10 und wurde mit Visual Studio Code 1.62.3 erstellt \n",
    "\n",
    "\n",
    "#### Arbeitsschritte im Code:\n",
    "\n",
    "> Vorarbeiten:   \n",
    "  - Notwendige Pandas Libraries aufrufen\n",
    "  - Serverprüfung auf funktionierende Verbindung zum Aleph-X-Server    \n",
    "\n",
    "\n",
    "> Daten abholen und einlesen:   \n",
    "  1. Buchhandelsdaten von Schweitzer \n",
    "  2. Aleph-Konkordanz Aleph-ID /Schweitzer ID  (erzeugt tagesaktuell per p-print-03 in Aleph)\n",
    "     - Aufbereiten der Daten: Schweitzer ID extrahieren und Aleph-ID mit Nullen auffüllen\n",
    "  3. Daten zusammenführen in einem df    \n",
    "\n",
    "\n",
    "> Daten aufbereiten:   \n",
    "  1. Buchhandelsdaten prüfen und vorbereiten\n",
    "     1. Identifizierung von Titeln in Aleph, die nicht mehr im Datensatz sind und schreiben in Datei \"ges02_loeschen_1\"\n",
    "     2. Dublettencheck innerhalb der Buchhandelsdaten\n",
    "     3. Trennung der Daten in \"in Aleph vorhanden\" und \"neu\"  \n",
    "  2. Bestandsabfragen:\n",
    "     1. Ganz neue Titel   \n",
    "        - Bestandsabgleich durch Abfragen (GES und EBX) auf dem Aleph-Server   \n",
    "     2. In Aleph vorhanden\n",
    "        - Bestandsabgleich durch Abfrage EBX auf dem Aleph-Server  \n",
    "     3. Exportvorbereitungen:\n",
    "        1. Neue Titel\n",
    "        2. In Aleph vorhandene Titel   \n",
    "            Identifizierung von zu löschenden Titeln \"ges02_loeschen_2\" und der zu aktualisierenden\n",
    "  3. Exportdateien aufbereiten:\n",
    "     1. Aufbereiten neuer Titel\n",
    "     2. Aufbereiten der vorhandenen Titel   \n",
    "\n",
    "\n",
    "> Informationssammlung\n",
    "   1. Log-Datei mit Rahmendaten wird fortlaufend geschrieben\n",
    "   2. Ausgabe bestimmter Titelgruppen als csv-Datei  \n",
    "\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vorarbeiten\n",
    "\n",
    "### Pandas Libraries laden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd                                                # für das Arbeiten mit der CSV-Datei\n",
    "import urllib.request                                              # für das Abrufen der URL\n",
    "import requests                                                    # für die Bestandsabfragen \n",
    "pd.options.mode.chained_assignment = None                          # default='warn' abschalten beim Beschreiben der neuen Spalten\n",
    "import time                                                        # für das Schreiben des Datums Logdatei und Excel-Export und Arbeiten mit dem Erscheinungsdatum\n",
    "import datetime                                                    # für das Berechnen des Updates\n",
    "import numpy as np                                                 # für das Bearbeiten von Spalten\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prüfung, ob die Verbindung zum Aleph-Server für Abfragen korrekt funktioniert:\n",
    "\n",
    "    Nur zugelassene IPs können diese Schnittstelle abfragen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Der Server antwortet korrekt\n"
     ]
    }
   ],
   "source": [
    "test= \"http://aleph.mpg.de/X?op=find&base=ges01&request=IBS=9783482648434\"\n",
    "\n",
    "reply = requests.get(test).text\n",
    "a = reply.find(\"Forbidden\")\n",
    "b =  reply.find(\"?xml\")\n",
    "\n",
    "if (a > 50):\n",
    "    print(\"Es gibt ein Problem mit dem Server\")\n",
    "if (b == 1):\n",
    "    print(\"Der Server antwortet korrekt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<?xml version = \"1.0\" encoding = \"UTF-8\"?>\n",
      "<find>\n",
      "<set_number>763086</set_number>\n",
      "<no_records>000000001</no_records>\n",
      "<no_entries>000000001</no_entries>\n",
      "<session-id>2NLNH7A198581QNDEYSKPI3INE5VRYS27IVKITI8U9JQLQJBYJ</session-id>\n",
      "</find>\n",
      " \n"
     ]
    }
   ],
   "source": [
    "test= \"http://aleph.mpg.de/X?op=find&base=ges01&request=IBS=9783865058041\"\n",
    "\n",
    "reply = requests.get(test).text \n",
    "\n",
    "print(reply) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datensätze abholen und einlesen\n",
    "\n",
    "# Erste Schritte manuell durchführen, um enthaltene Prüfroutinen im Blick zu behalten\n",
    "\n",
    "<hr>\n",
    "\n",
    "### 1. Datensätze von Schweitzer\n",
    "\n",
    "*einlesen in df*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./input/export.csv', <http.client.HTTPMessage at 0x2156c7bb070>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://content.schweitzer-online.de/static/content/export/mpifg/export.csv\"  # Abruf, der von Schweitzer zur Verfügung gestellten Daten\n",
    "checkout_file = \"./input/export.csv\"  \n",
    "urllib.request.urlretrieve(url, checkout_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./input/export.csv', encoding = 'UTF-8', sep=';' , keep_default_na=False) # muss encoding angeben und Trennzeichen, NaN (= leere Werte) direkt beim Import entfernen, da sie später Probleme machen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zeilen in Datei: 18319\n",
      "Object_IDs:      18319\n"
     ]
    }
   ],
   "source": [
    "#Aufgrund eines zusätzlichen Zeilenumbruchs im Datensatz gab es im Juni 2022 ein Problem, darum kleine Prüfroutine eingebaut ob in der Import-Datei die Anzahl der Datensätze mit der Anzahl der object-Ids übereinstimmt\n",
    "g = df.shape[0]\n",
    "h= df['object_id'].count()\n",
    "\n",
    "print(\"Zeilen in Datei:\", g)\n",
    "print(\"Object_IDs:     \", h)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ab dem nächsten Schritt kann Skript durchlaufen, Prüfroutinen sind erfolgt\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Aleph-Konkordanz Aleph-ID / Schweitzer ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = time.strftime('%Y%m%d')  # %H:%M:%S\n",
    "input_file = './input/ids'+now      #input_file wird tagesaktuell aus Aleph gezogen und auf diesem Wege mit der entsprechenden Endung eingelesen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Field</th>\n",
       "      <th>L</th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>62432</td>\n",
       "      <td>20</td>\n",
       "      <td>L</td>\n",
       "      <td>$$a160009340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>62433</td>\n",
       "      <td>20</td>\n",
       "      <td>L</td>\n",
       "      <td>$$a158945668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62435</td>\n",
       "      <td>20</td>\n",
       "      <td>L</td>\n",
       "      <td>$$a159450684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>62436</td>\n",
       "      <td>20</td>\n",
       "      <td>L</td>\n",
       "      <td>$$a156899389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>62437</td>\n",
       "      <td>20</td>\n",
       "      <td>L</td>\n",
       "      <td>$$a160055285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16492</th>\n",
       "      <td>80633</td>\n",
       "      <td>20</td>\n",
       "      <td>L</td>\n",
       "      <td>$$a2576512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16493</th>\n",
       "      <td>80634</td>\n",
       "      <td>20</td>\n",
       "      <td>L</td>\n",
       "      <td>$$a164587122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16494</th>\n",
       "      <td>80635</td>\n",
       "      <td>20</td>\n",
       "      <td>L</td>\n",
       "      <td>$$a162834053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16495</th>\n",
       "      <td>80636</td>\n",
       "      <td>20</td>\n",
       "      <td>L</td>\n",
       "      <td>$$a164805381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16496</th>\n",
       "      <td>80637</td>\n",
       "      <td>20</td>\n",
       "      <td>L</td>\n",
       "      <td>$$a163990169</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16497 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID  Field  L       Content\n",
       "0      62432     20  L  $$a160009340\n",
       "1      62433     20  L  $$a158945668\n",
       "2      62435     20  L  $$a159450684\n",
       "3      62436     20  L  $$a156899389\n",
       "4      62437     20  L  $$a160055285\n",
       "...      ...    ... ..           ...\n",
       "16492  80633     20  L    $$a2576512\n",
       "16493  80634     20  L  $$a164587122\n",
       "16494  80635     20  L  $$a162834053\n",
       "16495  80636     20  L  $$a164805381\n",
       "16496  80637     20  L  $$a163990169\n",
       "\n",
       "[16497 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_alephIDs = pd.read_fwf(input_file, encoding = 'UTF-8', sep='\\s\\s', header=None, keep_default_na=False) \n",
    "df_alephIDs.columns=[\"ID\",\"Field\",\"L\",\"Content\"]\n",
    "df_alephIDs\n",
    "\n",
    "#Spalte 0 = Aleph-IDs müsste vor Export mit Nullen aufgefüllt werden \n",
    "#Spalte 3 = object_id aus df, hier muss zum Abgleich $$a entfernt werden\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Datenfelder aufbereiten: Schweitzer-ID extrahieren und Aleph-ID ins richtige Format bringen*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        160009340\n",
       "1        158945668\n",
       "2        159450684\n",
       "3        156899389\n",
       "4        160055285\n",
       "           ...    \n",
       "16492      2576512\n",
       "16493    164587122\n",
       "16494    162834053\n",
       "16495    164805381\n",
       "16496    163990169\n",
       "Name: object_id, Length: 16497, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_alephIDs[\"object_id\"] = df_alephIDs[\"Content\"].astype(str).str.slice(start=3,stop=13).apply(int)   #Spalte mit object-Ids herausschneiden und wieder zur Zahl definieren\n",
    "\n",
    "df_alephIDs[\"object_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        000062432\n",
       "1        000062433\n",
       "2        000062435\n",
       "3        000062436\n",
       "4        000062437\n",
       "           ...    \n",
       "16492    000080633\n",
       "16493    000080634\n",
       "16494    000080635\n",
       "16495    000080636\n",
       "16496    000080637\n",
       "Name: ids, Length: 16497, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Aleph-ID-Spalte mit Nullen Auffüllen\n",
    "df_alephIDs[\"ids\"] = df_alephIDs['ID'].apply(lambda x: f\"{x:09d}\")\n",
    "df_alephIDs[\"ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "162793471    1\n",
       "161547093    1\n",
       "160541391    1\n",
       "163785079    1\n",
       "153502477    1\n",
       "            ..\n",
       "162883599    1\n",
       "160781568    1\n",
       "160087293    1\n",
       "146967803    1\n",
       "156993537    1\n",
       "Name: object_id, Length: 16497, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#nach Dubletten vom letzten Mal vorsichtshalber, check nach doppelten object-ids\n",
    "df_alephIDs[\"object_id\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Daten zu einem Frame zusammenführen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zusammenführung erfolgt einmal mit concat - erlaubt die nicht mehr verwendeten Aleph-IDs zu identifizieren \n",
    "# und einmal mit join, dann erhalte ich nur die Titel, die auch im neuen Datensatz sind zur weiteren Verarbeitung!\n",
    "df_oi= df.set_index(\"object_id\")                          #object-ID zum Index für beide Datenframes\n",
    "df_aleph_oi = df_alephIDs.set_index(\"object_id\")\n",
    "df_update_aleph = pd.concat([df_oi, df_aleph_oi], axis=1)\n",
    "\n",
    "df_update_join = df_oi.join(df_aleph_oi)                    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOG-Datei für den Prozess, zur Dokumentation des Imports und als Kontrollanzeige hier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl der enthaltenen Datensätze: 18319\n",
      "-------------------------\n",
      "Aleph-IDs anfangs 16497\n",
      "Aleph-IDs nach join 16486\n"
     ]
    }
   ],
   "source": [
    "x = df.shape[0]\n",
    "print('Anzahl der enthaltenen Datensätze:', x)\n",
    "#print('vorhandene ISBNs:', df_update[\"isbn_ean\"].shape[0])\n",
    "\n",
    "z = df_alephIDs[\"ids\"].count()\n",
    "y = df_update_join[\"ids\"].count()\n",
    "\n",
    "print('-------------------------')\n",
    "print('Aleph-IDs anfangs', z)\n",
    "print('Aleph-IDs nach join' , y)\n",
    "\n",
    "timestr = time.strftime('%d.%m.%Y - %H:%M')\n",
    "\n",
    "with open ('./log/pda_import_log.txt', 'a') as log:                                                  # Da diese Log-Datei nicht unmittelbar gebraucht wird, hier fortlaufendes Schreiben in eine Datei\n",
    "    log.write('Logdatei PDA-Import vom ')\n",
    "    log.write(timestr)\n",
    "    log.write('\\n------------------------------------------\\n')\n",
    "    log.write('Gelieferte Datensätze:             ' + str(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problemlösung der Aleph-Dubletten\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_alephIDs[\"object_id\"].value_counts\n",
    "\n",
    "df_aleph_einzel = df_alephIDs.drop_duplicates(\"object_id\", keep=False)  #Auslesen der Eintraege mit einzelner object_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_aleph_doppelt = df_alephIDs.groupby(\"object_id\").filter(lambda g: (g.nunique() >1).any()) #Doppelte object_ids rausziehen\n",
    "df_aleph_single = df_aleph_doppelt.sort_values(by=[\"object_id\", \"ids\"], ascending =False).drop_duplicates(subset=[\"object_id\"], keep='first')  #von Dubletten 1. behalten "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_aleph_vorhanden = df_aleph_einzel.append(df_aleph_single)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daten aufbereiten\n",
    "\n",
    "<hr>\n",
    "\n",
    "### 1. Identifizierung von Titeln in Aleph-Dubletten, die nicht mehr im Datensatz sind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isbn_ean</th>\n",
       "      <th>title</th>\n",
       "      <th>subtitle</th>\n",
       "      <th>contributor</th>\n",
       "      <th>publisher</th>\n",
       "      <th>series</th>\n",
       "      <th>thesis</th>\n",
       "      <th>edition_number</th>\n",
       "      <th>edition_text</th>\n",
       "      <th>media_type</th>\n",
       "      <th>...</th>\n",
       "      <th>cover</th>\n",
       "      <th>predecessor</th>\n",
       "      <th>follower</th>\n",
       "      <th>last_modified</th>\n",
       "      <th>watchlist_name</th>\n",
       "      <th>ID</th>\n",
       "      <th>Field</th>\n",
       "      <th>L</th>\n",
       "      <th>Content</th>\n",
       "      <th>ids</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>object_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>237277</th>\n",
       "      <td>9.78383e+12</td>\n",
       "      <td>Käuferverhalten</td>\n",
       "      <td>Eine marketingorientierte Einführung</td>\n",
       "      <td>Alfred Kuß;Torsten Tomczak;Silke Lennerts</td>\n",
       "      <td>UTB</td>\n",
       "      <td>Grundwissen der Ökonomik Band 1604</td>\n",
       "      <td></td>\n",
       "      <td>5</td>\n",
       "      <td>5., komplett überarbeitete Auflage 2017</td>\n",
       "      <td>hardcover</td>\n",
       "      <td>...</td>\n",
       "      <td>https://content.schweitzer-online.de/static/ca...</td>\n",
       "      <td>9783825216047</td>\n",
       "      <td></td>\n",
       "      <td>2022-07-17 19:23:57</td>\n",
       "      <td>Himbeere Wirtschaft #26</td>\n",
       "      <td>68192</td>\n",
       "      <td>20</td>\n",
       "      <td>L</td>\n",
       "      <td>$$a237277</td>\n",
       "      <td>000068192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259076</th>\n",
       "      <td>9.78387e+12</td>\n",
       "      <td>Geschlossene Gesellschaft</td>\n",
       "      <td>Ein Reichtumsbericht</td>\n",
       "      <td>Dennis Gastmann</td>\n",
       "      <td>Rowohlt Berlin</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>hardcover</td>\n",
       "      <td>...</td>\n",
       "      <td>https://content.schweitzer-online.de/static/ca...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2021-06-30 20:57:28</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1681954</th>\n",
       "      <td>9.789e+12</td>\n",
       "      <td>The Workers' Opposition in the Russian Communi...</td>\n",
       "      <td>Documents, 1919-30</td>\n",
       "      <td></td>\n",
       "      <td>Brill</td>\n",
       "      <td>Historical Materialism Book Series 236</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>hardcover</td>\n",
       "      <td>...</td>\n",
       "      <td>https://content.schweitzer-online.de/static/ca...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2022-08-22 19:13:46</td>\n",
       "      <td>diverse1</td>\n",
       "      <td>62977</td>\n",
       "      <td>20</td>\n",
       "      <td>L</td>\n",
       "      <td>$$a1681954</td>\n",
       "      <td>000062977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1958724</th>\n",
       "      <td>9.78042e+12</td>\n",
       "      <td>Population, Development and Welfare in the His...</td>\n",
       "      <td></td>\n",
       "      <td>Claudia Sunna</td>\n",
       "      <td>Routledge</td>\n",
       "      <td>Routledge Studies in the History of Economics</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>hardcover</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2022-08-16 17:34:53</td>\n",
       "      <td>brombeere Politik #43</td>\n",
       "      <td>72194</td>\n",
       "      <td>20</td>\n",
       "      <td>L</td>\n",
       "      <td>$$a1958724</td>\n",
       "      <td>000072194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2208209</th>\n",
       "      <td>9.78317e+12</td>\n",
       "      <td>Der Artenschutz im Bebauungsplanverfahren</td>\n",
       "      <td></td>\n",
       "      <td>Matthias Blessing;Eckart Scharmer</td>\n",
       "      <td>Kohlhammer</td>\n",
       "      <td>Kohlhammer Handbücher</td>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>3., aktualisierte Auflage 2022</td>\n",
       "      <td>hardcover</td>\n",
       "      <td>...</td>\n",
       "      <td>https://content.schweitzer-online.de/static/ca...</td>\n",
       "      <td>9783170225626</td>\n",
       "      <td></td>\n",
       "      <td>2022-08-30 19:15:23</td>\n",
       "      <td>brombeere Politik #64.2</td>\n",
       "      <td>77834</td>\n",
       "      <td>20</td>\n",
       "      <td>L</td>\n",
       "      <td>$$a2208209</td>\n",
       "      <td>000077834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165015356</th>\n",
       "      <td>9.78349e+12</td>\n",
       "      <td>Trauma, Hoffnung und Ernüchterung: Wahlergebni...</td>\n",
       "      <td></td>\n",
       "      <td>André Krause</td>\n",
       "      <td>Olms, Georg</td>\n",
       "      <td>Schriften aus dem Haus der Niederlande 12</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>2022</td>\n",
       "      <td>hardcover</td>\n",
       "      <td>...</td>\n",
       "      <td>https://content.schweitzer-online.de/static/ca...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2022-08-26 05:34:24</td>\n",
       "      <td>brombeere Politik #68</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165015365</th>\n",
       "      <td>9.78361e+12</td>\n",
       "      <td>MERKUR Gegründet 1947 als Deutsche Zeitschrift...</td>\n",
       "      <td>Nr. 880, Heft 9, September 2022</td>\n",
       "      <td>Christian Demand</td>\n",
       "      <td>Klett-Cotta</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>1. Auflage</td>\n",
       "      <td>hardcover</td>\n",
       "      <td>...</td>\n",
       "      <td>https://content.schweitzer-online.de/static/ca...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2022-08-28 18:58:41</td>\n",
       "      <td>Himbeere Wirtschaft #67.1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165173590</th>\n",
       "      <td>9.7802e+12</td>\n",
       "      <td>Comparative Politics, 4e</td>\n",
       "      <td>Integrating Theories, Methods, and Cases</td>\n",
       "      <td>J Tyler Dickovick;Jonathan Eastwood;Robin M Le...</td>\n",
       "      <td>Oxford University Press, USA</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "      <td>4th ed.</td>\n",
       "      <td>hardcover</td>\n",
       "      <td>...</td>\n",
       "      <td>https://content.schweitzer-online.de/static/ca...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2022-08-25 17:19:02</td>\n",
       "      <td>brombeere Politik #68</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165173742</th>\n",
       "      <td>9.78052e+12</td>\n",
       "      <td>Problems of Hemispheric Defense</td>\n",
       "      <td>Lectures Delivered under the Auspices of the C...</td>\n",
       "      <td>Committee on International Relations</td>\n",
       "      <td>University of California Press</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>hardcover</td>\n",
       "      <td>...</td>\n",
       "      <td>https://content.schweitzer-online.de/static/ca...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2022-08-26 17:27:54</td>\n",
       "      <td>brombeere Politik #68</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165173755</th>\n",
       "      <td>9.78052e+12</td>\n",
       "      <td>A Half Century of Municipal Reform</td>\n",
       "      <td>The History of the National Municipal League</td>\n",
       "      <td>Frank Mann Stewart</td>\n",
       "      <td>University of California Press</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>hardcover</td>\n",
       "      <td>...</td>\n",
       "      <td>https://content.schweitzer-online.de/static/ca...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2022-08-26 17:27:55</td>\n",
       "      <td>brombeere Politik #68</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18330 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              isbn_ean                                              title  \\\n",
       "object_id                                                                   \n",
       "237277     9.78383e+12                                    Käuferverhalten   \n",
       "259076     9.78387e+12                          Geschlossene Gesellschaft   \n",
       "1681954      9.789e+12  The Workers' Opposition in the Russian Communi...   \n",
       "1958724    9.78042e+12  Population, Development and Welfare in the His...   \n",
       "2208209    9.78317e+12          Der Artenschutz im Bebauungsplanverfahren   \n",
       "...                ...                                                ...   \n",
       "165015356  9.78349e+12  Trauma, Hoffnung und Ernüchterung: Wahlergebni...   \n",
       "165015365  9.78361e+12  MERKUR Gegründet 1947 als Deutsche Zeitschrift...   \n",
       "165173590   9.7802e+12                           Comparative Politics, 4e   \n",
       "165173742  9.78052e+12                    Problems of Hemispheric Defense   \n",
       "165173755  9.78052e+12                 A Half Century of Municipal Reform   \n",
       "\n",
       "                                                    subtitle  \\\n",
       "object_id                                                      \n",
       "237277                  Eine marketingorientierte Einführung   \n",
       "259076                                  Ein Reichtumsbericht   \n",
       "1681954                                   Documents, 1919-30   \n",
       "1958724                                                        \n",
       "2208209                                                        \n",
       "...                                                      ...   \n",
       "165015356                                                      \n",
       "165015365                    Nr. 880, Heft 9, September 2022   \n",
       "165173590           Integrating Theories, Methods, and Cases   \n",
       "165173742  Lectures Delivered under the Auspices of the C...   \n",
       "165173755       The History of the National Municipal League   \n",
       "\n",
       "                                                 contributor  \\\n",
       "object_id                                                      \n",
       "237277             Alfred Kuß;Torsten Tomczak;Silke Lennerts   \n",
       "259076                                       Dennis Gastmann   \n",
       "1681954                                                        \n",
       "1958724                                        Claudia Sunna   \n",
       "2208209                    Matthias Blessing;Eckart Scharmer   \n",
       "...                                                      ...   \n",
       "165015356                                       André Krause   \n",
       "165015365                                   Christian Demand   \n",
       "165173590  J Tyler Dickovick;Jonathan Eastwood;Robin M Le...   \n",
       "165173742               Committee on International Relations   \n",
       "165173755                                 Frank Mann Stewart   \n",
       "\n",
       "                                publisher  \\\n",
       "object_id                                   \n",
       "237277                                UTB   \n",
       "259076                     Rowohlt Berlin   \n",
       "1681954                             Brill   \n",
       "1958724                         Routledge   \n",
       "2208209                        Kohlhammer   \n",
       "...                                   ...   \n",
       "165015356                     Olms, Georg   \n",
       "165015365                     Klett-Cotta   \n",
       "165173590    Oxford University Press, USA   \n",
       "165173742  University of California Press   \n",
       "165173755  University of California Press   \n",
       "\n",
       "                                                  series thesis  \\\n",
       "object_id                                                         \n",
       "237277                Grundwissen der Ökonomik Band 1604          \n",
       "259076                                                            \n",
       "1681954           Historical Materialism Book Series 236          \n",
       "1958724    Routledge Studies in the History of Economics          \n",
       "2208209                            Kohlhammer Handbücher          \n",
       "...                                                  ...    ...   \n",
       "165015356      Schriften aus dem Haus der Niederlande 12          \n",
       "165015365                                                         \n",
       "165173590                                                         \n",
       "165173742                                                         \n",
       "165173755                                                         \n",
       "\n",
       "          edition_number                             edition_text media_type  \\\n",
       "object_id                                                                      \n",
       "237277                 5  5., komplett überarbeitete Auflage 2017  hardcover   \n",
       "259076                                                             hardcover   \n",
       "1681954                                                            hardcover   \n",
       "1958724                1                                           hardcover   \n",
       "2208209                3           3., aktualisierte Auflage 2022  hardcover   \n",
       "...                  ...                                      ...        ...   \n",
       "165015356              1                                     2022  hardcover   \n",
       "165015365              1                               1. Auflage  hardcover   \n",
       "165173590              4                                  4th ed.  hardcover   \n",
       "165173742                                                          hardcover   \n",
       "165173755                                                          hardcover   \n",
       "\n",
       "           ...                                              cover  \\\n",
       "object_id  ...                                                      \n",
       "237277     ...  https://content.schweitzer-online.de/static/ca...   \n",
       "259076     ...  https://content.schweitzer-online.de/static/ca...   \n",
       "1681954    ...  https://content.schweitzer-online.de/static/ca...   \n",
       "1958724    ...                                                      \n",
       "2208209    ...  https://content.schweitzer-online.de/static/ca...   \n",
       "...        ...                                                ...   \n",
       "165015356  ...  https://content.schweitzer-online.de/static/ca...   \n",
       "165015365  ...  https://content.schweitzer-online.de/static/ca...   \n",
       "165173590  ...  https://content.schweitzer-online.de/static/ca...   \n",
       "165173742  ...  https://content.schweitzer-online.de/static/ca...   \n",
       "165173755  ...  https://content.schweitzer-online.de/static/ca...   \n",
       "\n",
       "             predecessor follower        last_modified  \\\n",
       "object_id                                                \n",
       "237277     9783825216047           2022-07-17 19:23:57   \n",
       "259076                             2021-06-30 20:57:28   \n",
       "1681954                            2022-08-22 19:13:46   \n",
       "1958724                            2022-08-16 17:34:53   \n",
       "2208209    9783170225626           2022-08-30 19:15:23   \n",
       "...                  ...      ...                  ...   \n",
       "165015356                          2022-08-26 05:34:24   \n",
       "165015365                          2022-08-28 18:58:41   \n",
       "165173590                          2022-08-25 17:19:02   \n",
       "165173742                          2022-08-26 17:27:54   \n",
       "165173755                          2022-08-26 17:27:55   \n",
       "\n",
       "                      watchlist_name     ID Field     L     Content        ids  \n",
       "object_id                                                                       \n",
       "237277       Himbeere Wirtschaft #26  68192    20     L   $$a237277  000068192  \n",
       "259076                                 None  None  None        None       None  \n",
       "1681954                     diverse1  62977    20     L  $$a1681954  000062977  \n",
       "1958724        brombeere Politik #43  72194    20     L  $$a1958724  000072194  \n",
       "2208209      brombeere Politik #64.2  77834    20     L  $$a2208209  000077834  \n",
       "...                              ...    ...   ...   ...         ...        ...  \n",
       "165015356      brombeere Politik #68   None  None  None        None       None  \n",
       "165015365  Himbeere Wirtschaft #67.1   None  None  None        None       None  \n",
       "165173590      brombeere Politik #68   None  None  None        None       None  \n",
       "165173742      brombeere Politik #68   None  None  None        None       None  \n",
       "165173755      brombeere Politik #68   None  None  None        None       None  \n",
       "\n",
       "[18330 rows x 27 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_update_aleph.replace({np.nan: None})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aleph_loeschen = df_update_aleph[df_update_aleph['isbn_ean'].isna()]  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isbn_ean</th>\n",
       "      <th>title</th>\n",
       "      <th>subtitle</th>\n",
       "      <th>contributor</th>\n",
       "      <th>publisher</th>\n",
       "      <th>series</th>\n",
       "      <th>thesis</th>\n",
       "      <th>edition_number</th>\n",
       "      <th>edition_text</th>\n",
       "      <th>media_type</th>\n",
       "      <th>...</th>\n",
       "      <th>cover</th>\n",
       "      <th>predecessor</th>\n",
       "      <th>follower</th>\n",
       "      <th>last_modified</th>\n",
       "      <th>watchlist_name</th>\n",
       "      <th>ID</th>\n",
       "      <th>Field</th>\n",
       "      <th>L</th>\n",
       "      <th>Content</th>\n",
       "      <th>ids</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>object_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>159570449</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>63592.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>L</td>\n",
       "      <td>$$a159570449</td>\n",
       "      <td>000063592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159740806</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65524.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>L</td>\n",
       "      <td>$$a159740806</td>\n",
       "      <td>000065524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159753610</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70867.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>L</td>\n",
       "      <td>$$a159753610</td>\n",
       "      <td>000070867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162508516</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65468.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>L</td>\n",
       "      <td>$$a162508516</td>\n",
       "      <td>000065468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162611902</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>69308.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>L</td>\n",
       "      <td>$$a162611902</td>\n",
       "      <td>000069308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162832986</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>77543.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>L</td>\n",
       "      <td>$$a162832986</td>\n",
       "      <td>000077543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163228775</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>69416.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>L</td>\n",
       "      <td>$$a163228775</td>\n",
       "      <td>000069416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163581258</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>71348.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>L</td>\n",
       "      <td>$$a163581258</td>\n",
       "      <td>000071348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163867262</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>73076.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>L</td>\n",
       "      <td>$$a163867262</td>\n",
       "      <td>000073076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164005753</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>78104.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>L</td>\n",
       "      <td>$$a164005753</td>\n",
       "      <td>000078104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164879132</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80297.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>L</td>\n",
       "      <td>$$a164879132</td>\n",
       "      <td>000080297</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           isbn_ean title subtitle contributor publisher series thesis  \\\n",
       "object_id                                                                \n",
       "159570449       NaN   NaN      NaN         NaN       NaN    NaN    NaN   \n",
       "159740806       NaN   NaN      NaN         NaN       NaN    NaN    NaN   \n",
       "159753610       NaN   NaN      NaN         NaN       NaN    NaN    NaN   \n",
       "162508516       NaN   NaN      NaN         NaN       NaN    NaN    NaN   \n",
       "162611902       NaN   NaN      NaN         NaN       NaN    NaN    NaN   \n",
       "162832986       NaN   NaN      NaN         NaN       NaN    NaN    NaN   \n",
       "163228775       NaN   NaN      NaN         NaN       NaN    NaN    NaN   \n",
       "163581258       NaN   NaN      NaN         NaN       NaN    NaN    NaN   \n",
       "163867262       NaN   NaN      NaN         NaN       NaN    NaN    NaN   \n",
       "164005753       NaN   NaN      NaN         NaN       NaN    NaN    NaN   \n",
       "164879132       NaN   NaN      NaN         NaN       NaN    NaN    NaN   \n",
       "\n",
       "          edition_number edition_text media_type  ... cover predecessor  \\\n",
       "object_id                                         ...                     \n",
       "159570449            NaN          NaN        NaN  ...   NaN         NaN   \n",
       "159740806            NaN          NaN        NaN  ...   NaN         NaN   \n",
       "159753610            NaN          NaN        NaN  ...   NaN         NaN   \n",
       "162508516            NaN          NaN        NaN  ...   NaN         NaN   \n",
       "162611902            NaN          NaN        NaN  ...   NaN         NaN   \n",
       "162832986            NaN          NaN        NaN  ...   NaN         NaN   \n",
       "163228775            NaN          NaN        NaN  ...   NaN         NaN   \n",
       "163581258            NaN          NaN        NaN  ...   NaN         NaN   \n",
       "163867262            NaN          NaN        NaN  ...   NaN         NaN   \n",
       "164005753            NaN          NaN        NaN  ...   NaN         NaN   \n",
       "164879132            NaN          NaN        NaN  ...   NaN         NaN   \n",
       "\n",
       "          follower last_modified watchlist_name       ID Field  L  \\\n",
       "object_id                                                           \n",
       "159570449      NaN           NaN            NaN  63592.0  20.0  L   \n",
       "159740806      NaN           NaN            NaN  65524.0  20.0  L   \n",
       "159753610      NaN           NaN            NaN  70867.0  20.0  L   \n",
       "162508516      NaN           NaN            NaN  65468.0  20.0  L   \n",
       "162611902      NaN           NaN            NaN  69308.0  20.0  L   \n",
       "162832986      NaN           NaN            NaN  77543.0  20.0  L   \n",
       "163228775      NaN           NaN            NaN  69416.0  20.0  L   \n",
       "163581258      NaN           NaN            NaN  71348.0  20.0  L   \n",
       "163867262      NaN           NaN            NaN  73076.0  20.0  L   \n",
       "164005753      NaN           NaN            NaN  78104.0  20.0  L   \n",
       "164879132      NaN           NaN            NaN  80297.0  20.0  L   \n",
       "\n",
       "                Content        ids  \n",
       "object_id                           \n",
       "159570449  $$a159570449  000063592  \n",
       "159740806  $$a159740806  000065524  \n",
       "159753610  $$a159753610  000070867  \n",
       "162508516  $$a162508516  000065468  \n",
       "162611902  $$a162611902  000069308  \n",
       "162832986  $$a162832986  000077543  \n",
       "163228775  $$a163228775  000069416  \n",
       "163581258  $$a163581258  000071348  \n",
       "163867262  $$a163867262  000073076  \n",
       "164005753  $$a164005753  000078104  \n",
       "164879132  $$a164879132  000080297  \n",
       "\n",
       "[11 rows x 27 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_aleph_loeschen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schreiben der Loeschen-datei!\n",
    "\n",
    "with open(\"./output/ges02_weg\", \"w\", encoding=\"utf-8\") as fa:  #durch das Encoding hier, kommen Sonderzeichen richtig rüber\n",
    "    for i in df_aleph_loeschen.index:\n",
    "        fa.write(df_aleph_loeschen[\"ids\"][i]+'GES02'+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## 2. Dublettencheck innerhalb gelieferten Buchhandelsdaten \n",
    "\n",
    "Aufgaben im Rahmen des Dublettencheck:\n",
    "1. Dublettenkontrolle anhand von Titel, Untertitel und Autor \n",
    "   - Zunächst Behebung der unsauberen Titel / Untertitel-Trennung für korrekteren Abgleich\n",
    "   - Trennung der Datensätze in Dubletten und \"Einzeltitel\"\n",
    "     - Einzeltitel werden direkt für Bestandsprüfung vorgemerkt\n",
    "     - Dubletten werden auf neueste Version reduziert und diese der Bestandsprüfungsdatei hinzugefügt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Die Dublettenkontrolle Anhand von Titel, Untertitel und Autor\n",
    "\n",
    "*Entfernen von Untertiteln aus der Titelspalte, Extrahieren von Untertiteln und Abgleich mit Untertitelspalte und Schreiben der vorhandenen Informationen in neue Untertitel-Spalte.   \n",
    "Durch diese Spalte werden ca. 1/3 mehr Dubletten erkannt, als ohne die Bereinigung. *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_update_join[df_update_join['isbn_ean'].notna()]  #jetzt alle die zu verarbeiten sind rausziehen\n",
    "df.reset_index(inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "neu = df[\"title\"].str.split(':', n = 1, expand = True)  #Titel am 1. Doppelpunkt splitten und getrennt in neue Felder schreiben\n",
    "df[\"title_sep\"]= neu[0]\n",
    "df[\"subtitle_sep\"]= neu[1]\n",
    "\n",
    "df[\"subtitle_sep\"] = df[\"subtitle_sep\"].replace(np.nan, '', regex=True) #NaN-Werte stören, darum raus damit ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison = np.where(df[\"subtitle\"] == df[\"subtitle_sep\"], '', df[\"subtitle\"])    # Abgleich - wenn in beiden das Gleiche steht, dann ursprüngliches \"Subtitle\"-Feld nehmen\n",
    "df[\"subtitle_comparison\"] = comparison  \n",
    "\n",
    "comparison2 = np.where(df[\"subtitle\"] < df[\"subtitle_sep\"], df[\"subtitle_sep\"], '') # Wenn nur in \"subtitle_sep\" Infos stehen, diese übernehmen, das ist noch nicht ganz sauber, da hier manchmal anderes steht als in \"subtitle\"\n",
    "df[\"subtitle_comparison2\"] = comparison2 \n",
    "\n",
    "df[\"subtitle_all\"] = df[\"subtitle_comparison\"]+df[\"subtitle_comparison2\"]          # Beide Informationen in neuer Subtitle-Spalte zusammenführen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"short_title\"] = df[\"title_sep\"] + ' ' + df[\"subtitle_all\"] + ' / ' + df[\"contributor\"]  # aus den bereinigten Daten einen Kurztitel erzeugen, der dann für den Dublettencheck verwendet wird"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dubletten = df.groupby(\"short_title\").filter(lambda g: (g.nunique() >1).any()) # schreibt alle mehrfach vorhandenen Titel in ein eigenes Datenframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_dubl_einspielen = df_dubletten.sort_values(by=[\"short_title\", \"publication_year\"], ascending =False).drop_duplicates(subset=[\"short_title\"], keep='first')   # sortiert Dubletten nach Jahr und schreibt den jeweils ersten (= neuesten) Eintrag in neues Dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ohne_dubletten = df.drop_duplicates(\"short_title\", keep=False)       #durch \"\"keep=False\" werden alle nicht-Dubletten rausgezogen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dubl_nicht_einspielen = df_dubletten.sort_values(by=[\"short_title\", \"publication_year\"], ascending =False).drop_duplicates(subset=[\"short_title\"], keep=False)\n",
    "\n",
    "#Kontrolle, ob es in Dubletten Titel gibt, die schon in Aleph sind\n",
    "df_dubl_nicht_einspielen[\"ids\"].count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_einspielen = df_ohne_dubletten.append(df_dubl_einspielen)                    # die ausgewählten Dubletten und alle Nicht-Dubletten werden in ein Datenframe zusammengeführt\n",
    "df_einspielen.reset_index(inplace=True)                                         # für weitere Bearbeitung index-reset nötig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## 3. Überblick zu den Daten und Trennen in \"in Aleph vorhanden\" und \"neu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zum Einspielen: 16016\n",
      "Davon in Aleph: 14810\n",
      "Neue Titel: 1206\n"
     ]
    }
   ],
   "source": [
    "m = df_einspielen.shape[0]\n",
    "n = df_einspielen[\"ids\"].count()\n",
    "print(\"Zum Einspielen:\", m)\n",
    "print(\"Davon in Aleph:\", n)\n",
    "print(\"Neue Titel:\", m-n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14810"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_in_aleph = df_einspielen.dropna(subset=['ids'])\n",
    "df_in_aleph.reset_index(inplace=True)\n",
    "df_in_aleph.shape[0]\n",
    "\n",
    "# zur Prüfung am GES und Ebx Bestand geprüft werden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1206"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ganz_neu = df_einspielen[df_einspielen['ids'].isnull()]\n",
    "\n",
    "df_ganz_neu.reset_index(inplace=True)\n",
    "df_ganz_neu.shape[0]\n",
    "\n",
    "# diese müssen ebenfalls am Ges und Ebx Bestand geprüft werden, durch Trennung der Sets schnellere Bearbeitung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Bestandsabfragen\n",
    "\n",
    "\n",
    "\n",
    "*URLs für die Abfrage über den X-Server unseres Bibliothekssystems werden erzeugt und über die ISBN eine Abfrage auf Bestand gemacht. Die Abfrage funktioniert nur für zugelassene IPs (darum oben die Prüfung).  \n",
    "Für die Abfrage in unseren Bestand ist die ISBN sehr gut, da in den Titeldaten alle im Buch befindlichen ISBNs - auch die anderer Ausgabeformen - mit übernommen sind. Beim MPG-Ebooks Katalog handelt sich um Daten von Verlagen, die sich in ihrer Qualität und Informationsumfang sehr unterscheiden. Hier wird noch zu prüfen sein, inwieweit ein anderer Abfragemechansimus gewählt werden muss.*  \n",
    "\n",
    "### 1. Ganz neue Titel  \n",
    "\n",
    "= df_ganz_neu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ganz_neu[\"url_ges\"] = df_ganz_neu[\"isbn_ean\"].apply(lambda x: f\"ges_link{x}\".replace('ges_link','http://aleph.mpg.de/X?op=find&base=ges01&request=IBS='))\n",
    "\n",
    "#Es funktionierte nicht, dass die URLs an die vorhandenen ISBNs einfach so angefügt werden, darum der Workaround mit einem Platzhalter, der sich dann über replace vom richtigen Link überschreiben ließ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### URLs für Ebooks-Katalog erzeugen "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ganz_neu[\"url_ebx\"] = df_ganz_neu[\"isbn_ean\"].apply(lambda x: f\"ebx_link{x}\".replace('ebx_link', 'http://aleph.mpg.de/X?op=find&base=ebx01&request=IBN='))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Abfragen beim Server\n",
    "\n",
    "##### Zunächst für die Daten des MPIfG \n",
    "\n",
    "*Vorgehensweise: Abfrage und Sammeln der Antworten in einer Datei, diese Antworten werden dann in Ausdrücke \"übersetzt\" - \"vorhanden\" und \"neu\" und diese Daten in eine Spalte ins Dataframe zur weiteren Auswertung übertragen.   \n",
    "Schwierigkeit hier war, die Sammlung der Antworten zu den einzelnen Titeln, um sie in das Datenframe einzuspielen. Der störende XML-Header der Antworten wird erst gar nicht in die Datei geschrieben.   *   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./input/server_responses', 'w') as fn:  \n",
    "    for url in df_ganz_neu[\"url_ges\"]:\n",
    "        reply = requests.get(url).text\n",
    "        a = reply.replace('<?xml version = \"1.0\" encoding = \"UTF-8\"?>', '') \n",
    "        fn.write(a)\n",
    "\n",
    "with open('./input/server_responses', 'r') as f:\n",
    "    with open('./input/server_responses_transfered', 'w') as fr:\n",
    "        for line in f:\n",
    "            if 'empty' in line:\n",
    "                fr.write('neu\\n')\n",
    "            elif 'no_records' in line:\n",
    "                fr.write('vorhanden\\n')\n",
    "\n",
    "df_fwf = pd.read_fwf('./input/server_responses_transfered', names=[\"Abfrage_ges\"])\n",
    "df_result = df_ganz_neu.join(df_fwf)                    #df_result = pd.concat([df_ganz_neu, df_fwf], axis=1), funktioniert nicht mehr                  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Randnotiz: \n",
    "    Bei 2400 Titels brauchte der Abgleich ca 350 Sekunden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl der eingelesenen Datensätze: 1206 \n",
      "Anzahl der Antworten vom Server:    1206\n"
     ]
    }
   ],
   "source": [
    "#Kontrollabfrage, ob für alle Titel auch Treffer da sind, wird mittelfristig rausfallen\n",
    "x = df_ganz_neu.shape[0]\n",
    "y = df_fwf.shape[0]\n",
    "print('Anzahl der eingelesenen Datensätze:', x, '\\nAnzahl der Antworten vom Server:   ', y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Datenabgleich mit dem Bestand des MPG Ebooks-Katalog\n",
    "\n",
    "*Vorgehensweise analog Bestandsabfrage MPI.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./input/server_responses_ebx', 'w') as fn:  \n",
    "    for url in df_result[\"url_ebx\"]:\n",
    "        reply = requests.get(url).text\n",
    "        a = reply.replace('<?xml version = \"1.0\" encoding = \"UTF-8\"?>', '') \n",
    "        fn.write(a)\n",
    "\n",
    "with open('./input/server_responses_ebx', 'r') as f:\n",
    "    with open('./input/server_responses_transfered_ebx', 'w') as fr:\n",
    "        for line in f:\n",
    "            if 'empty' in line:\n",
    "                fr.write('neu\\n')\n",
    "            elif 'no_records' in line:\n",
    "                fr.write('vorhanden\\n')\n",
    "\n",
    "df_fwf_ebx = pd.read_fwf('./input/server_responses_transfered_ebx', names=[\"Abfrage_ebx\"])\n",
    "df_result_neu = df_result.join(df_fwf_ebx)           #df_result_neu = pd.concat([df_result, df_fwf_ebx], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl der eingelesenen Datensätze: 1206 \n",
      "Anzahl der Antworten vom Server:    1206\n"
     ]
    }
   ],
   "source": [
    "#Kontrollabfrage, ob für alle Titel auch Treffer da sind\n",
    "x = df_result_neu.shape[0]\n",
    "y = df_fwf_ebx.shape[0]\n",
    "print('Anzahl der eingelesenen Datensätze:', x, '\\nAnzahl der Antworten vom Server:   ', y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Titel in Aleph vorhanden\n",
    "\n",
    "= df_in_aleph\n",
    "\n",
    "*Da erworbene Bücher nicht manuell gelöscht werden auch hier wieder Abgleich mit beiden Datenquellen.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_in_aleph[\"url_ges\"] = df_in_aleph[\"isbn_ean\"].apply(lambda x: f\"ges_link{x}\".replace('ges_link', 'http://aleph.mpg.de/X?op=find&base=ges01&request=IBS='))\n",
    "\n",
    "df_in_aleph[\"url_ebx\"] = df_in_aleph[\"isbn_ean\"].apply(lambda x: f\"ebx_link{x}\".replace('ebx_link', 'http://aleph.mpg.de/X?op=find&base=ebx01&request=IBN='))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Abfragen beim Server\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./input/server_responses2', 'w') as fn:  \n",
    "    for url in df_in_aleph[\"url_ges\"]:\n",
    "        reply = requests.get(url).text\n",
    "        a = reply.replace('<?xml version = \"1.0\" encoding = \"UTF-8\"?>', '') \n",
    "        fn.write(a)\n",
    "\n",
    "with open('./input/server_responses2', 'r') as f:\n",
    "    with open('./input/server_responses_transfered2', 'w') as fr:\n",
    "        for line in f:\n",
    "            if 'empty' in line:\n",
    "                fr.write('neu\\n')\n",
    "            elif 'no_records' in line:\n",
    "                fr.write('vorhanden\\n')\n",
    "\n",
    "df_fwf_ges = pd.read_fwf('./input/server_responses_transfered2', names=[\"Abfrage_ges\"])\n",
    "df_result2 = df_in_aleph.join(df_fwf_ges)               #df_result2 = pd.concat([df_in_aleph, df_fwf_ges], axis=1)             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl der eingelesenen Datensätze: 14810 \n",
      "Anzahl der Antworten vom Server:    14810\n"
     ]
    }
   ],
   "source": [
    "#Kontrollabfrage, ob für alle Titel auch Treffer da sind, wird mittelfristig rausfallen\n",
    "x = df_in_aleph.shape[0]\n",
    "y = df_fwf_ges.shape[0]\n",
    "print('Anzahl der eingelesenen Datensätze:', x, '\\nAnzahl der Antworten vom Server:   ', y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        neu\n",
       "1        neu\n",
       "2        neu\n",
       "3        neu\n",
       "4        neu\n",
       "        ... \n",
       "14805    neu\n",
       "14806    neu\n",
       "14807    neu\n",
       "14808    neu\n",
       "14809    neu\n",
       "Name: Abfrage_ges, Length: 14810, dtype: object"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result2['Abfrage_ges']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./input/server_responses_ebx2', 'w') as fn:  \n",
    "    for url in df_result2[\"url_ebx\"]:\n",
    "        reply = requests.get(url).text\n",
    "        a = reply.replace('<?xml version = \"1.0\" encoding = \"UTF-8\"?>', '') \n",
    "        fn.write(a)\n",
    "\n",
    "with open('./input/server_responses_ebx2', 'r') as f:\n",
    "    with open('./input/server_responses_transfered_ebx2', 'w') as fr:\n",
    "        for line in f:\n",
    "            if 'empty' in line:\n",
    "                fr.write('neu\\n')\n",
    "            elif 'no_records' in line:\n",
    "                fr.write('vorhanden\\n')\n",
    "\n",
    "df_fwf_ebx2 = pd.read_fwf('./input/server_responses_transfered_ebx2', names=[\"Abfrage_ebx\"])\n",
    "df_result_in_aleph = df_result2.join(df_fwf_ebx2)           #df_result_in_aleph = pd.concat([df_result2, df_fwf_ebx2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl der eingelesenen Datensätze: 14810 \n",
      "Anzahl der Antworten vom Server:    14810\n"
     ]
    }
   ],
   "source": [
    "#Kontrollabfrage, ob für alle Titel auch Treffer da sind\n",
    "x = df_result_in_aleph.shape[0]\n",
    "y = df_fwf_ebx2.shape[0]\n",
    "print('Anzahl der eingelesenen Datensätze:', x, '\\nAnzahl der Antworten vom Server:   ', y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## 3. Exportvorbereitungen \n",
    "\n",
    "\n",
    "### 1. Neue Titel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_neu_nicht_einspielen =  df_result_neu.drop(df_result_neu[(df_result_neu[\"Abfrage_ebx\"]== 'neu') & (df_result_neu[\"Abfrage_ges\"] == 'neu')].index)          \n",
    "# alle Titel rausholen, die in einer der beiden Datenbanken vorhanden waren, diese werden mit den vorhandenen aus Update unten in Excel geschrieben\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Jetzt Extraktion der Titel zum Einspielen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_neu_aleph_einspielen = df_result_neu.loc[((df_result_neu[\"Abfrage_ebx\"]== 'neu') & (df_result_neu[\"Abfrage_ges\"] == 'neu'))]   #das sind die komplett neuen Titel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. In Aleph vorhandene Titel\n",
    "\n",
    "*Hier ist der Fall: was im Ebooks-Katalog vorhanden ist, muss gelöscht werden*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_0</th>\n",
       "      <th>index</th>\n",
       "      <th>object_id</th>\n",
       "      <th>isbn_ean</th>\n",
       "      <th>title</th>\n",
       "      <th>subtitle</th>\n",
       "      <th>contributor</th>\n",
       "      <th>publisher</th>\n",
       "      <th>series</th>\n",
       "      <th>thesis</th>\n",
       "      <th>...</th>\n",
       "      <th>title_sep</th>\n",
       "      <th>subtitle_sep</th>\n",
       "      <th>subtitle_comparison</th>\n",
       "      <th>subtitle_comparison2</th>\n",
       "      <th>subtitle_all</th>\n",
       "      <th>short_title</th>\n",
       "      <th>url_ges</th>\n",
       "      <th>url_ebx</th>\n",
       "      <th>Abfrage_ges</th>\n",
       "      <th>Abfrage_ebx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>22</td>\n",
       "      <td>42</td>\n",
       "      <td>158087569</td>\n",
       "      <td>9789813340541</td>\n",
       "      <td>Chinese Finance Policy for a New Era</td>\n",
       "      <td></td>\n",
       "      <td>Dexu  He</td>\n",
       "      <td>Palgrave Macmillan</td>\n",
       "      <td>Progress in Mathematics</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>Chinese Finance Policy for a New Era</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Chinese Finance Policy for a New Era  / Dexu  He</td>\n",
       "      <td>http://aleph.mpg.de/X?op=find&amp;base=ges01&amp;reque...</td>\n",
       "      <td>http://aleph.mpg.de/X?op=find&amp;base=ebx01&amp;reque...</td>\n",
       "      <td>vorhanden</td>\n",
       "      <td>neu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>68</td>\n",
       "      <td>102</td>\n",
       "      <td>160081601</td>\n",
       "      <td>9783030769970</td>\n",
       "      <td>Trade Wins or Trade Wars</td>\n",
       "      <td>The Perceptions and Knowledge in the Free Trad...</td>\n",
       "      <td>Bogna Gawronska-Nowak;Piotr Lis;Joanna Koniecz...</td>\n",
       "      <td>Palgrave Pivot</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>Trade Wins or Trade Wars</td>\n",
       "      <td></td>\n",
       "      <td>The Perceptions and Knowledge in the Free Trad...</td>\n",
       "      <td></td>\n",
       "      <td>The Perceptions and Knowledge in the Free Trad...</td>\n",
       "      <td>Trade Wins or Trade Wars The Perceptions and K...</td>\n",
       "      <td>http://aleph.mpg.de/X?op=find&amp;base=ges01&amp;reque...</td>\n",
       "      <td>http://aleph.mpg.de/X?op=find&amp;base=ebx01&amp;reque...</td>\n",
       "      <td>vorhanden</td>\n",
       "      <td>neu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>807</th>\n",
       "      <td>892</td>\n",
       "      <td>1366</td>\n",
       "      <td>159795100</td>\n",
       "      <td>9781905816767</td>\n",
       "      <td>Devon Women in Public and Professional Life, 1...</td>\n",
       "      <td>Votes, Voices and Vocations</td>\n",
       "      <td>Julia Neville;Mitzi Auchterlonie;Paul Auchterl...</td>\n",
       "      <td>University of Exeter Press</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>Devon Women in Public and Professional Life, 1...</td>\n",
       "      <td></td>\n",
       "      <td>Votes, Voices and Vocations</td>\n",
       "      <td></td>\n",
       "      <td>Votes, Voices and Vocations</td>\n",
       "      <td>Devon Women in Public and Professional Life, 1...</td>\n",
       "      <td>http://aleph.mpg.de/X?op=find&amp;base=ges01&amp;reque...</td>\n",
       "      <td>http://aleph.mpg.de/X?op=find&amp;base=ebx01&amp;reque...</td>\n",
       "      <td>neu</td>\n",
       "      <td>vor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1339</th>\n",
       "      <td>1480</td>\n",
       "      <td>2171</td>\n",
       "      <td>159952292</td>\n",
       "      <td>9783030754440</td>\n",
       "      <td>Macroeconomic Responses to the COVID-19 Pandemic</td>\n",
       "      <td>Policies from Southeast Europe</td>\n",
       "      <td>Vidakovic, Neven</td>\n",
       "      <td>Palgrave Macmillan</td>\n",
       "      <td>Progress in Mathematics</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>Macroeconomic Responses to the COVID-19 Pandemic</td>\n",
       "      <td></td>\n",
       "      <td>Policies from Southeast Europe</td>\n",
       "      <td></td>\n",
       "      <td>Policies from Southeast Europe</td>\n",
       "      <td>Macroeconomic Responses to the COVID-19 Pandem...</td>\n",
       "      <td>http://aleph.mpg.de/X?op=find&amp;base=ges01&amp;reque...</td>\n",
       "      <td>http://aleph.mpg.de/X?op=find&amp;base=ebx01&amp;reque...</td>\n",
       "      <td>vorhanden</td>\n",
       "      <td>neu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2304</th>\n",
       "      <td>2535</td>\n",
       "      <td>3584</td>\n",
       "      <td>162110160</td>\n",
       "      <td>9780197558485</td>\n",
       "      <td>Problem-Solving Sociology</td>\n",
       "      <td>A Guide for Students</td>\n",
       "      <td>Monica Prasad</td>\n",
       "      <td>Oxford University Press Inc</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>Problem-Solving Sociology</td>\n",
       "      <td></td>\n",
       "      <td>A Guide for Students</td>\n",
       "      <td></td>\n",
       "      <td>A Guide for Students</td>\n",
       "      <td>Problem-Solving Sociology A Guide for Students...</td>\n",
       "      <td>http://aleph.mpg.de/X?op=find&amp;base=ges01&amp;reque...</td>\n",
       "      <td>http://aleph.mpg.de/X?op=find&amp;base=ebx01&amp;reque...</td>\n",
       "      <td>vorhanden</td>\n",
       "      <td>neu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4044</th>\n",
       "      <td>4374</td>\n",
       "      <td>5934</td>\n",
       "      <td>139532232</td>\n",
       "      <td>9781138210592</td>\n",
       "      <td>Governance and Business Models for Sustainable...</td>\n",
       "      <td></td>\n",
       "      <td>Atle Midttun</td>\n",
       "      <td>Routledge</td>\n",
       "      <td>Routledge Studies in Management, Organizations...</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>Governance and Business Models for Sustainable...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Governance and Business Models for Sustainable...</td>\n",
       "      <td>http://aleph.mpg.de/X?op=find&amp;base=ges01&amp;reque...</td>\n",
       "      <td>http://aleph.mpg.de/X?op=find&amp;base=ebx01&amp;reque...</td>\n",
       "      <td>neu</td>\n",
       "      <td>vor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7649</th>\n",
       "      <td>8250</td>\n",
       "      <td>11031</td>\n",
       "      <td>163666825</td>\n",
       "      <td>9789463727259</td>\n",
       "      <td>Contesting Cosmopolitan Europe</td>\n",
       "      <td>Euroscepticism, Crisis and Borders</td>\n",
       "      <td>James Foley</td>\n",
       "      <td>Amsterdam University Press</td>\n",
       "      <td>Protest and Social Movements</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>Contesting Cosmopolitan Europe</td>\n",
       "      <td></td>\n",
       "      <td>Euroscepticism, Crisis and Borders</td>\n",
       "      <td></td>\n",
       "      <td>Euroscepticism, Crisis and Borders</td>\n",
       "      <td>Contesting Cosmopolitan Europe Euroscepticism,...</td>\n",
       "      <td>http://aleph.mpg.de/X?op=find&amp;base=ges01&amp;reque...</td>\n",
       "      <td>http://aleph.mpg.de/X?op=find&amp;base=ebx01&amp;reque...</td>\n",
       "      <td>neu</td>\n",
       "      <td>vor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12009</th>\n",
       "      <td>12728</td>\n",
       "      <td>16886</td>\n",
       "      <td>164342394</td>\n",
       "      <td>9789463721660</td>\n",
       "      <td>Urban Life and Intellectual Crisis in Middle-P...</td>\n",
       "      <td></td>\n",
       "      <td>Christian de Pee</td>\n",
       "      <td>Amsterdam University Press</td>\n",
       "      <td>Global Chinese Histories, 250-1650</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>Urban Life and Intellectual Crisis in Middle-P...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Urban Life and Intellectual Crisis in Middle-P...</td>\n",
       "      <td>http://aleph.mpg.de/X?op=find&amp;base=ges01&amp;reque...</td>\n",
       "      <td>http://aleph.mpg.de/X?op=find&amp;base=ebx01&amp;reque...</td>\n",
       "      <td>neu</td>\n",
       "      <td>vor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13114</th>\n",
       "      <td>14098</td>\n",
       "      <td>11961</td>\n",
       "      <td>162042227</td>\n",
       "      <td>9780472075324</td>\n",
       "      <td>The Repoliticization of the Welfare State</td>\n",
       "      <td></td>\n",
       "      <td>Ian P McManus</td>\n",
       "      <td>The University of Michigan Press</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>The Repoliticization of the Welfare State</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>The Repoliticization of the Welfare State  / I...</td>\n",
       "      <td>http://aleph.mpg.de/X?op=find&amp;base=ges01&amp;reque...</td>\n",
       "      <td>http://aleph.mpg.de/X?op=find&amp;base=ebx01&amp;reque...</td>\n",
       "      <td>neu</td>\n",
       "      <td>vor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13295</th>\n",
       "      <td>14297</td>\n",
       "      <td>2629</td>\n",
       "      <td>157149402</td>\n",
       "      <td>9781526148353</td>\n",
       "      <td>The Eu and Crisis Response</td>\n",
       "      <td></td>\n",
       "      <td>Roger Mac Ginty</td>\n",
       "      <td>Manchester University Press</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>The Eu and Crisis Response</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>The Eu and Crisis Response  / Roger Mac Ginty</td>\n",
       "      <td>http://aleph.mpg.de/X?op=find&amp;base=ges01&amp;reque...</td>\n",
       "      <td>http://aleph.mpg.de/X?op=find&amp;base=ebx01&amp;reque...</td>\n",
       "      <td>neu</td>\n",
       "      <td>vor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13695</th>\n",
       "      <td>14762</td>\n",
       "      <td>7891</td>\n",
       "      <td>160147566</td>\n",
       "      <td>9780472132942</td>\n",
       "      <td>Pride, Not Prejudice</td>\n",
       "      <td>National Identity as a Pacifying Force in East...</td>\n",
       "      <td>Eunbin Chung</td>\n",
       "      <td>The University of Michigan Press</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>Pride, Not Prejudice</td>\n",
       "      <td></td>\n",
       "      <td>National Identity as a Pacifying Force in East...</td>\n",
       "      <td></td>\n",
       "      <td>National Identity as a Pacifying Force in East...</td>\n",
       "      <td>Pride, Not Prejudice National Identity as a Pa...</td>\n",
       "      <td>http://aleph.mpg.de/X?op=find&amp;base=ges01&amp;reque...</td>\n",
       "      <td>http://aleph.mpg.de/X?op=find&amp;base=ebx01&amp;reque...</td>\n",
       "      <td>neu</td>\n",
       "      <td>vor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13813</th>\n",
       "      <td>14897</td>\n",
       "      <td>7420</td>\n",
       "      <td>159942077</td>\n",
       "      <td>9780472132898</td>\n",
       "      <td>Normalization in World Politics</td>\n",
       "      <td></td>\n",
       "      <td>Nicolas Lemay-Hebert;Gezim Visoka</td>\n",
       "      <td>The University of Michigan Press</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>Normalization in World Politics</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Normalization in World Politics  / Nicolas Lem...</td>\n",
       "      <td>http://aleph.mpg.de/X?op=find&amp;base=ges01&amp;reque...</td>\n",
       "      <td>http://aleph.mpg.de/X?op=find&amp;base=ebx01&amp;reque...</td>\n",
       "      <td>neu</td>\n",
       "      <td>vor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13832</th>\n",
       "      <td>14920</td>\n",
       "      <td>14751</td>\n",
       "      <td>163415368</td>\n",
       "      <td>9780520333246</td>\n",
       "      <td>Natural Resources and the State</td>\n",
       "      <td>The Political Economy of Resource Management</td>\n",
       "      <td>Oran R. Young</td>\n",
       "      <td>University of California Press</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>Natural Resources and the State</td>\n",
       "      <td></td>\n",
       "      <td>The Political Economy of Resource Management</td>\n",
       "      <td></td>\n",
       "      <td>The Political Economy of Resource Management</td>\n",
       "      <td>Natural Resources and the State The Political ...</td>\n",
       "      <td>http://aleph.mpg.de/X?op=find&amp;base=ges01&amp;reque...</td>\n",
       "      <td>http://aleph.mpg.de/X?op=find&amp;base=ebx01&amp;reque...</td>\n",
       "      <td>vorhanden</td>\n",
       "      <td>neu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14133</th>\n",
       "      <td>15251</td>\n",
       "      <td>7704</td>\n",
       "      <td>160102455</td>\n",
       "      <td>9780472132928</td>\n",
       "      <td>Human Capital versus Basic Income</td>\n",
       "      <td>Ideology and Models of Anti-Poverty Programs i...</td>\n",
       "      <td>Fabian A Borges</td>\n",
       "      <td>The University of Michigan Press</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>Human Capital versus Basic Income</td>\n",
       "      <td></td>\n",
       "      <td>Ideology and Models of Anti-Poverty Programs i...</td>\n",
       "      <td></td>\n",
       "      <td>Ideology and Models of Anti-Poverty Programs i...</td>\n",
       "      <td>Human Capital versus Basic Income Ideology and...</td>\n",
       "      <td>http://aleph.mpg.de/X?op=find&amp;base=ges01&amp;reque...</td>\n",
       "      <td>http://aleph.mpg.de/X?op=find&amp;base=ebx01&amp;reque...</td>\n",
       "      <td>neu</td>\n",
       "      <td>vor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14199</th>\n",
       "      <td>15330</td>\n",
       "      <td>9283</td>\n",
       "      <td>161172588</td>\n",
       "      <td>9780472075232</td>\n",
       "      <td>Global Cities in Latin America and Asia</td>\n",
       "      <td>Welcome to the Twenty-first Century</td>\n",
       "      <td>Pablo Baisotti</td>\n",
       "      <td>The University of Michigan Press</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>Global Cities in Latin America and Asia</td>\n",
       "      <td></td>\n",
       "      <td>Welcome to the Twenty-first Century</td>\n",
       "      <td></td>\n",
       "      <td>Welcome to the Twenty-first Century</td>\n",
       "      <td>Global Cities in Latin America and Asia Welcom...</td>\n",
       "      <td>http://aleph.mpg.de/X?op=find&amp;base=ges01&amp;reque...</td>\n",
       "      <td>http://aleph.mpg.de/X?op=find&amp;base=ebx01&amp;reque...</td>\n",
       "      <td>neu</td>\n",
       "      <td>vor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14292</th>\n",
       "      <td>15431</td>\n",
       "      <td>13166</td>\n",
       "      <td>162733763</td>\n",
       "      <td>9780472055449</td>\n",
       "      <td>Evading the Patronage Trap</td>\n",
       "      <td>Interest Representation in Mexico</td>\n",
       "      <td>Brian Palmer-Rubin</td>\n",
       "      <td>The University of Michigan Press</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>Evading the Patronage Trap</td>\n",
       "      <td></td>\n",
       "      <td>Interest Representation in Mexico</td>\n",
       "      <td></td>\n",
       "      <td>Interest Representation in Mexico</td>\n",
       "      <td>Evading the Patronage Trap Interest Representa...</td>\n",
       "      <td>http://aleph.mpg.de/X?op=find&amp;base=ges01&amp;reque...</td>\n",
       "      <td>http://aleph.mpg.de/X?op=find&amp;base=ebx01&amp;reque...</td>\n",
       "      <td>neu</td>\n",
       "      <td>vor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14343</th>\n",
       "      <td>15490</td>\n",
       "      <td>8492</td>\n",
       "      <td>162090627</td>\n",
       "      <td>9780472075188</td>\n",
       "      <td>Electoral Campaigns, Media, and the New World ...</td>\n",
       "      <td></td>\n",
       "      <td>David Taras;Richard Davis</td>\n",
       "      <td>The University of Michigan Press</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>Electoral Campaigns, Media, and the New World ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Electoral Campaigns, Media, and the New World ...</td>\n",
       "      <td>http://aleph.mpg.de/X?op=find&amp;base=ges01&amp;reque...</td>\n",
       "      <td>http://aleph.mpg.de/X?op=find&amp;base=ebx01&amp;reque...</td>\n",
       "      <td>neu</td>\n",
       "      <td>vor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14399</th>\n",
       "      <td>15551</td>\n",
       "      <td>8809</td>\n",
       "      <td>163475166</td>\n",
       "      <td>9780198831488</td>\n",
       "      <td>Digital Economic Policy</td>\n",
       "      <td>The Economics of Digital Markets from a Europe...</td>\n",
       "      <td>Mario Mariniello</td>\n",
       "      <td>Oxford University Press</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>Digital Economic Policy</td>\n",
       "      <td></td>\n",
       "      <td>The Economics of Digital Markets from a Europe...</td>\n",
       "      <td></td>\n",
       "      <td>The Economics of Digital Markets from a Europe...</td>\n",
       "      <td>Digital Economic Policy The Economics of Digit...</td>\n",
       "      <td>http://aleph.mpg.de/X?op=find&amp;base=ges01&amp;reque...</td>\n",
       "      <td>http://aleph.mpg.de/X?op=find&amp;base=ebx01&amp;reque...</td>\n",
       "      <td>vorhanden</td>\n",
       "      <td>neu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14437</th>\n",
       "      <td>15592</td>\n",
       "      <td>6519</td>\n",
       "      <td>159627731</td>\n",
       "      <td>9780472132829</td>\n",
       "      <td>Delegating Responsibility</td>\n",
       "      <td>International Cooperation on Migration in the ...</td>\n",
       "      <td>Nicholas R. Micinski</td>\n",
       "      <td>The University of Michigan Press</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>Delegating Responsibility</td>\n",
       "      <td></td>\n",
       "      <td>International Cooperation on Migration in the ...</td>\n",
       "      <td></td>\n",
       "      <td>International Cooperation on Migration in the ...</td>\n",
       "      <td>Delegating Responsibility International Cooper...</td>\n",
       "      <td>http://aleph.mpg.de/X?op=find&amp;base=ges01&amp;reque...</td>\n",
       "      <td>http://aleph.mpg.de/X?op=find&amp;base=ebx01&amp;reque...</td>\n",
       "      <td>neu</td>\n",
       "      <td>vor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14524</th>\n",
       "      <td>15685</td>\n",
       "      <td>8009</td>\n",
       "      <td>160813946</td>\n",
       "      <td>9780472132980</td>\n",
       "      <td>Compound Containment</td>\n",
       "      <td>A Reigning Power's Military-Economic Counterme...</td>\n",
       "      <td>Dong Jung Kim</td>\n",
       "      <td>The University of Michigan Press</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>Compound Containment</td>\n",
       "      <td></td>\n",
       "      <td>A Reigning Power's Military-Economic Counterme...</td>\n",
       "      <td></td>\n",
       "      <td>A Reigning Power's Military-Economic Counterme...</td>\n",
       "      <td>Compound Containment A Reigning Power's Milita...</td>\n",
       "      <td>http://aleph.mpg.de/X?op=find&amp;base=ges01&amp;reque...</td>\n",
       "      <td>http://aleph.mpg.de/X?op=find&amp;base=ebx01&amp;reque...</td>\n",
       "      <td>neu</td>\n",
       "      <td>vor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14547</th>\n",
       "      <td>15714</td>\n",
       "      <td>77</td>\n",
       "      <td>159856392</td>\n",
       "      <td>9780367478704</td>\n",
       "      <td>Climate Crisis Economics</td>\n",
       "      <td></td>\n",
       "      <td>Stuart P. M. Mackintosh</td>\n",
       "      <td>Routledge</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>Climate Crisis Economics</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Climate Crisis Economics  / Stuart P. M. Macki...</td>\n",
       "      <td>http://aleph.mpg.de/X?op=find&amp;base=ges01&amp;reque...</td>\n",
       "      <td>http://aleph.mpg.de/X?op=find&amp;base=ebx01&amp;reque...</td>\n",
       "      <td>neu</td>\n",
       "      <td>vor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       level_0  index  object_id       isbn_ean  \\\n",
       "14          22     42  158087569  9789813340541   \n",
       "50          68    102  160081601  9783030769970   \n",
       "807        892   1366  159795100  9781905816767   \n",
       "1339      1480   2171  159952292  9783030754440   \n",
       "2304      2535   3584  162110160  9780197558485   \n",
       "4044      4374   5934  139532232  9781138210592   \n",
       "7649      8250  11031  163666825  9789463727259   \n",
       "12009    12728  16886  164342394  9789463721660   \n",
       "13114    14098  11961  162042227  9780472075324   \n",
       "13295    14297   2629  157149402  9781526148353   \n",
       "13695    14762   7891  160147566  9780472132942   \n",
       "13813    14897   7420  159942077  9780472132898   \n",
       "13832    14920  14751  163415368  9780520333246   \n",
       "14133    15251   7704  160102455  9780472132928   \n",
       "14199    15330   9283  161172588  9780472075232   \n",
       "14292    15431  13166  162733763  9780472055449   \n",
       "14343    15490   8492  162090627  9780472075188   \n",
       "14399    15551   8809  163475166  9780198831488   \n",
       "14437    15592   6519  159627731  9780472132829   \n",
       "14524    15685   8009  160813946  9780472132980   \n",
       "14547    15714     77  159856392  9780367478704   \n",
       "\n",
       "                                                   title  \\\n",
       "14                  Chinese Finance Policy for a New Era   \n",
       "50                              Trade Wins or Trade Wars   \n",
       "807    Devon Women in Public and Professional Life, 1...   \n",
       "1339    Macroeconomic Responses to the COVID-19 Pandemic   \n",
       "2304                           Problem-Solving Sociology   \n",
       "4044   Governance and Business Models for Sustainable...   \n",
       "7649                      Contesting Cosmopolitan Europe   \n",
       "12009  Urban Life and Intellectual Crisis in Middle-P...   \n",
       "13114          The Repoliticization of the Welfare State   \n",
       "13295                         The Eu and Crisis Response   \n",
       "13695                               Pride, Not Prejudice   \n",
       "13813                    Normalization in World Politics   \n",
       "13832                    Natural Resources and the State   \n",
       "14133                  Human Capital versus Basic Income   \n",
       "14199            Global Cities in Latin America and Asia   \n",
       "14292                         Evading the Patronage Trap   \n",
       "14343  Electoral Campaigns, Media, and the New World ...   \n",
       "14399                            Digital Economic Policy   \n",
       "14437                          Delegating Responsibility   \n",
       "14524                               Compound Containment   \n",
       "14547                           Climate Crisis Economics   \n",
       "\n",
       "                                                subtitle  \\\n",
       "14                                                         \n",
       "50     The Perceptions and Knowledge in the Free Trad...   \n",
       "807                          Votes, Voices and Vocations   \n",
       "1339                      Policies from Southeast Europe   \n",
       "2304                                A Guide for Students   \n",
       "4044                                                       \n",
       "7649                  Euroscepticism, Crisis and Borders   \n",
       "12009                                                      \n",
       "13114                                                      \n",
       "13295                                                      \n",
       "13695  National Identity as a Pacifying Force in East...   \n",
       "13813                                                      \n",
       "13832       The Political Economy of Resource Management   \n",
       "14133  Ideology and Models of Anti-Poverty Programs i...   \n",
       "14199                Welcome to the Twenty-first Century   \n",
       "14292                  Interest Representation in Mexico   \n",
       "14343                                                      \n",
       "14399  The Economics of Digital Markets from a Europe...   \n",
       "14437  International Cooperation on Migration in the ...   \n",
       "14524  A Reigning Power's Military-Economic Counterme...   \n",
       "14547                                                      \n",
       "\n",
       "                                             contributor  \\\n",
       "14                                              Dexu  He   \n",
       "50     Bogna Gawronska-Nowak;Piotr Lis;Joanna Koniecz...   \n",
       "807    Julia Neville;Mitzi Auchterlonie;Paul Auchterl...   \n",
       "1339                                    Vidakovic, Neven   \n",
       "2304                                       Monica Prasad   \n",
       "4044                                        Atle Midttun   \n",
       "7649                                         James Foley   \n",
       "12009                                   Christian de Pee   \n",
       "13114                                      Ian P McManus   \n",
       "13295                                    Roger Mac Ginty   \n",
       "13695                                       Eunbin Chung   \n",
       "13813                  Nicolas Lemay-Hebert;Gezim Visoka   \n",
       "13832                                      Oran R. Young   \n",
       "14133                                    Fabian A Borges   \n",
       "14199                                     Pablo Baisotti   \n",
       "14292                                 Brian Palmer-Rubin   \n",
       "14343                          David Taras;Richard Davis   \n",
       "14399                                   Mario Mariniello   \n",
       "14437                               Nicholas R. Micinski   \n",
       "14524                                      Dong Jung Kim   \n",
       "14547                            Stuart P. M. Mackintosh   \n",
       "\n",
       "                              publisher  \\\n",
       "14                   Palgrave Macmillan   \n",
       "50                       Palgrave Pivot   \n",
       "807          University of Exeter Press   \n",
       "1339                 Palgrave Macmillan   \n",
       "2304        Oxford University Press Inc   \n",
       "4044                          Routledge   \n",
       "7649         Amsterdam University Press   \n",
       "12009        Amsterdam University Press   \n",
       "13114  The University of Michigan Press   \n",
       "13295       Manchester University Press   \n",
       "13695  The University of Michigan Press   \n",
       "13813  The University of Michigan Press   \n",
       "13832    University of California Press   \n",
       "14133  The University of Michigan Press   \n",
       "14199  The University of Michigan Press   \n",
       "14292  The University of Michigan Press   \n",
       "14343  The University of Michigan Press   \n",
       "14399           Oxford University Press   \n",
       "14437  The University of Michigan Press   \n",
       "14524  The University of Michigan Press   \n",
       "14547                         Routledge   \n",
       "\n",
       "                                                  series thesis  ...  \\\n",
       "14                               Progress in Mathematics         ...   \n",
       "50                                                               ...   \n",
       "807                                                              ...   \n",
       "1339                             Progress in Mathematics         ...   \n",
       "2304                                                             ...   \n",
       "4044   Routledge Studies in Management, Organizations...         ...   \n",
       "7649                        Protest and Social Movements         ...   \n",
       "12009                 Global Chinese Histories, 250-1650         ...   \n",
       "13114                                                            ...   \n",
       "13295                                                            ...   \n",
       "13695                                                            ...   \n",
       "13813                                                            ...   \n",
       "13832                                                            ...   \n",
       "14133                                                            ...   \n",
       "14199                                                            ...   \n",
       "14292                                                            ...   \n",
       "14343                                                            ...   \n",
       "14399                                                            ...   \n",
       "14437                                                            ...   \n",
       "14524                                                            ...   \n",
       "14547                                                            ...   \n",
       "\n",
       "                                               title_sep subtitle_sep  \\\n",
       "14                  Chinese Finance Policy for a New Era                \n",
       "50                              Trade Wins or Trade Wars                \n",
       "807    Devon Women in Public and Professional Life, 1...                \n",
       "1339    Macroeconomic Responses to the COVID-19 Pandemic                \n",
       "2304                           Problem-Solving Sociology                \n",
       "4044   Governance and Business Models for Sustainable...                \n",
       "7649                      Contesting Cosmopolitan Europe                \n",
       "12009  Urban Life and Intellectual Crisis in Middle-P...                \n",
       "13114          The Repoliticization of the Welfare State                \n",
       "13295                         The Eu and Crisis Response                \n",
       "13695                               Pride, Not Prejudice                \n",
       "13813                    Normalization in World Politics                \n",
       "13832                    Natural Resources and the State                \n",
       "14133                  Human Capital versus Basic Income                \n",
       "14199            Global Cities in Latin America and Asia                \n",
       "14292                         Evading the Patronage Trap                \n",
       "14343  Electoral Campaigns, Media, and the New World ...                \n",
       "14399                            Digital Economic Policy                \n",
       "14437                          Delegating Responsibility                \n",
       "14524                               Compound Containment                \n",
       "14547                           Climate Crisis Economics                \n",
       "\n",
       "                                     subtitle_comparison subtitle_comparison2  \\\n",
       "14                                                                              \n",
       "50     The Perceptions and Knowledge in the Free Trad...                        \n",
       "807                          Votes, Voices and Vocations                        \n",
       "1339                      Policies from Southeast Europe                        \n",
       "2304                                A Guide for Students                        \n",
       "4044                                                                            \n",
       "7649                  Euroscepticism, Crisis and Borders                        \n",
       "12009                                                                           \n",
       "13114                                                                           \n",
       "13295                                                                           \n",
       "13695  National Identity as a Pacifying Force in East...                        \n",
       "13813                                                                           \n",
       "13832       The Political Economy of Resource Management                        \n",
       "14133  Ideology and Models of Anti-Poverty Programs i...                        \n",
       "14199                Welcome to the Twenty-first Century                        \n",
       "14292                  Interest Representation in Mexico                        \n",
       "14343                                                                           \n",
       "14399  The Economics of Digital Markets from a Europe...                        \n",
       "14437  International Cooperation on Migration in the ...                        \n",
       "14524  A Reigning Power's Military-Economic Counterme...                        \n",
       "14547                                                                           \n",
       "\n",
       "                                            subtitle_all  \\\n",
       "14                                                         \n",
       "50     The Perceptions and Knowledge in the Free Trad...   \n",
       "807                          Votes, Voices and Vocations   \n",
       "1339                      Policies from Southeast Europe   \n",
       "2304                                A Guide for Students   \n",
       "4044                                                       \n",
       "7649                  Euroscepticism, Crisis and Borders   \n",
       "12009                                                      \n",
       "13114                                                      \n",
       "13295                                                      \n",
       "13695  National Identity as a Pacifying Force in East...   \n",
       "13813                                                      \n",
       "13832       The Political Economy of Resource Management   \n",
       "14133  Ideology and Models of Anti-Poverty Programs i...   \n",
       "14199                Welcome to the Twenty-first Century   \n",
       "14292                  Interest Representation in Mexico   \n",
       "14343                                                      \n",
       "14399  The Economics of Digital Markets from a Europe...   \n",
       "14437  International Cooperation on Migration in the ...   \n",
       "14524  A Reigning Power's Military-Economic Counterme...   \n",
       "14547                                                      \n",
       "\n",
       "                                             short_title  \\\n",
       "14      Chinese Finance Policy for a New Era  / Dexu  He   \n",
       "50     Trade Wins or Trade Wars The Perceptions and K...   \n",
       "807    Devon Women in Public and Professional Life, 1...   \n",
       "1339   Macroeconomic Responses to the COVID-19 Pandem...   \n",
       "2304   Problem-Solving Sociology A Guide for Students...   \n",
       "4044   Governance and Business Models for Sustainable...   \n",
       "7649   Contesting Cosmopolitan Europe Euroscepticism,...   \n",
       "12009  Urban Life and Intellectual Crisis in Middle-P...   \n",
       "13114  The Repoliticization of the Welfare State  / I...   \n",
       "13295      The Eu and Crisis Response  / Roger Mac Ginty   \n",
       "13695  Pride, Not Prejudice National Identity as a Pa...   \n",
       "13813  Normalization in World Politics  / Nicolas Lem...   \n",
       "13832  Natural Resources and the State The Political ...   \n",
       "14133  Human Capital versus Basic Income Ideology and...   \n",
       "14199  Global Cities in Latin America and Asia Welcom...   \n",
       "14292  Evading the Patronage Trap Interest Representa...   \n",
       "14343  Electoral Campaigns, Media, and the New World ...   \n",
       "14399  Digital Economic Policy The Economics of Digit...   \n",
       "14437  Delegating Responsibility International Cooper...   \n",
       "14524  Compound Containment A Reigning Power's Milita...   \n",
       "14547  Climate Crisis Economics  / Stuart P. M. Macki...   \n",
       "\n",
       "                                                 url_ges  \\\n",
       "14     http://aleph.mpg.de/X?op=find&base=ges01&reque...   \n",
       "50     http://aleph.mpg.de/X?op=find&base=ges01&reque...   \n",
       "807    http://aleph.mpg.de/X?op=find&base=ges01&reque...   \n",
       "1339   http://aleph.mpg.de/X?op=find&base=ges01&reque...   \n",
       "2304   http://aleph.mpg.de/X?op=find&base=ges01&reque...   \n",
       "4044   http://aleph.mpg.de/X?op=find&base=ges01&reque...   \n",
       "7649   http://aleph.mpg.de/X?op=find&base=ges01&reque...   \n",
       "12009  http://aleph.mpg.de/X?op=find&base=ges01&reque...   \n",
       "13114  http://aleph.mpg.de/X?op=find&base=ges01&reque...   \n",
       "13295  http://aleph.mpg.de/X?op=find&base=ges01&reque...   \n",
       "13695  http://aleph.mpg.de/X?op=find&base=ges01&reque...   \n",
       "13813  http://aleph.mpg.de/X?op=find&base=ges01&reque...   \n",
       "13832  http://aleph.mpg.de/X?op=find&base=ges01&reque...   \n",
       "14133  http://aleph.mpg.de/X?op=find&base=ges01&reque...   \n",
       "14199  http://aleph.mpg.de/X?op=find&base=ges01&reque...   \n",
       "14292  http://aleph.mpg.de/X?op=find&base=ges01&reque...   \n",
       "14343  http://aleph.mpg.de/X?op=find&base=ges01&reque...   \n",
       "14399  http://aleph.mpg.de/X?op=find&base=ges01&reque...   \n",
       "14437  http://aleph.mpg.de/X?op=find&base=ges01&reque...   \n",
       "14524  http://aleph.mpg.de/X?op=find&base=ges01&reque...   \n",
       "14547  http://aleph.mpg.de/X?op=find&base=ges01&reque...   \n",
       "\n",
       "                                                 url_ebx  Abfrage_ges  \\\n",
       "14     http://aleph.mpg.de/X?op=find&base=ebx01&reque...    vorhanden   \n",
       "50     http://aleph.mpg.de/X?op=find&base=ebx01&reque...    vorhanden   \n",
       "807    http://aleph.mpg.de/X?op=find&base=ebx01&reque...          neu   \n",
       "1339   http://aleph.mpg.de/X?op=find&base=ebx01&reque...    vorhanden   \n",
       "2304   http://aleph.mpg.de/X?op=find&base=ebx01&reque...    vorhanden   \n",
       "4044   http://aleph.mpg.de/X?op=find&base=ebx01&reque...          neu   \n",
       "7649   http://aleph.mpg.de/X?op=find&base=ebx01&reque...          neu   \n",
       "12009  http://aleph.mpg.de/X?op=find&base=ebx01&reque...          neu   \n",
       "13114  http://aleph.mpg.de/X?op=find&base=ebx01&reque...          neu   \n",
       "13295  http://aleph.mpg.de/X?op=find&base=ebx01&reque...          neu   \n",
       "13695  http://aleph.mpg.de/X?op=find&base=ebx01&reque...          neu   \n",
       "13813  http://aleph.mpg.de/X?op=find&base=ebx01&reque...          neu   \n",
       "13832  http://aleph.mpg.de/X?op=find&base=ebx01&reque...    vorhanden   \n",
       "14133  http://aleph.mpg.de/X?op=find&base=ebx01&reque...          neu   \n",
       "14199  http://aleph.mpg.de/X?op=find&base=ebx01&reque...          neu   \n",
       "14292  http://aleph.mpg.de/X?op=find&base=ebx01&reque...          neu   \n",
       "14343  http://aleph.mpg.de/X?op=find&base=ebx01&reque...          neu   \n",
       "14399  http://aleph.mpg.de/X?op=find&base=ebx01&reque...    vorhanden   \n",
       "14437  http://aleph.mpg.de/X?op=find&base=ebx01&reque...          neu   \n",
       "14524  http://aleph.mpg.de/X?op=find&base=ebx01&reque...          neu   \n",
       "14547  http://aleph.mpg.de/X?op=find&base=ebx01&reque...          neu   \n",
       "\n",
       "      Abfrage_ebx  \n",
       "14            neu  \n",
       "50            neu  \n",
       "807           vor  \n",
       "1339          neu  \n",
       "2304          neu  \n",
       "4044          vor  \n",
       "7649          vor  \n",
       "12009         vor  \n",
       "13114         vor  \n",
       "13295         vor  \n",
       "13695         vor  \n",
       "13813         vor  \n",
       "13832         neu  \n",
       "14133         vor  \n",
       "14199         vor  \n",
       "14292         vor  \n",
       "14343         vor  \n",
       "14399         neu  \n",
       "14437         vor  \n",
       "14524         vor  \n",
       "14547         vor  \n",
       "\n",
       "[21 rows x 40 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_in_aleph_nicht_einspielen = df_result_in_aleph.drop(df_result_in_aleph[(df_result_in_aleph[\"Abfrage_ebx\"] == 'neu') & (df_result_in_aleph[\"Abfrage_ges\"] == 'neu')].index) \n",
    "df_in_aleph_nicht_einspielen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erzeugen der Datei zum Löschen der Titel\n",
    "\n",
    "with open(\"./output/ges02_weg\", \"a\", encoding=\"utf-8\") as fa:  #durch das Encoding hier, kommen Sonderzeichen richtig rüber\n",
    "    for i in df_in_aleph_nicht_einspielen.index:\n",
    "        fa.write(df_in_aleph_nicht_einspielen[\"ids\"][i]+'GES02'+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Für die Statistik und Kontrolle zusammenführen aller Titel, die nicht eingespielt werden und Ausgabe in einer CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gesamt_nicht_einspielen = df_in_aleph_nicht_einspielen.append(df_neu_nicht_einspielen)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = time.strftime(\"%Y_%m_%d\")                                              # Zeit erfassen für Dateibenennung\n",
    "\n",
    "df_gesamt_nicht_einspielen[\"object_id\"] = df_gesamt_nicht_einspielen.object_id.astype(str)  # wandelt die spalte von Int64 zu Object um, so dass es in Excel korrekt eingelesen wird\n",
    "df_gesamt_nicht_einspielen[\"isbn_ean\"] = df_gesamt_nicht_einspielen.isbn_ean.astype(str)\n",
    "df_gesamt_nicht_einspielen = df_gesamt_nicht_einspielen.drop(columns=[\"url_ebx\", \"url_ges\", \"cover\", \"title_sep\", \"subtitle_comparison\", \"subtitle_comparison2\", \"subtitle_all\", \"subtitle_sep\"]) # unnötige Spalten entfernen\n",
    "\n",
    "df_neu_nicht_einspielen.to_csv('./output/Vorhandene_Titel_'+date+'.csv')   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Jetzt Extraktion der Titel zum Updaten:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_in_aleph_update = df_result_in_aleph.loc[(df_result_in_aleph[\"Abfrage_ebx\"]== 'neu') & (df_result_in_aleph[\"Abfrage_ges\"] == 'neu')] # prüfen, ob es wirklich ein Datenupdate gab, sonst nicht neu einspielen??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "#### Für die Logdatei Ermittlung verschiedener Zahlen und hier zur direkten Ansicht ausgegeben"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kleine Statistik:\n",
      "===================================== \n",
      "Gelieferte Datensätze:              18319 \n",
      "-------------------------------------------- \n",
      "Sätze ohne Dubletten                13789 \n",
      "   Dubletten:               4530 \n",
      "   Auswahl zum Einspielen   2227 \n",
      "   in Aleph löschen         0 \n",
      "Zu prüfende Datensätze:             16016 \n",
      "-------------------------------------------- \n",
      "Prüfung Titel in Aleph:             14810 \n",
      "   Davon als Update         14789 \n",
      "   Davon in Aleph löschen   21 \n",
      "Prüfung neue Titel    :             1206 \n",
      "   Davon ganz neu           390 \n",
      "   Davon bereits Bestand    816 \n",
      "-------------------------------------------- \n",
      "Titel, die in Aleph verarbeitet werden:  15179 \n",
      "-------------------------------------------- \n",
      "Datensätze GES02 vor Einspielen:    16497 \n",
      "Nicht mehr im Export               - 11 \n",
      "Titel in Aleph löschen, da Bestand - 21 \n",
      "Zu löschen, da Dublette            - 0 \n",
      "Neue Titel für Aleph               + 390 \n",
      "-------------------------------------------- \n",
      "In Aleph nach Einspielen:           16855\n"
     ]
    }
   ],
   "source": [
    "#Kontrollmechanismus, ob für alle Titel auch Treffer da sind\n",
    "x = df.shape[0]\n",
    "a = df_ohne_dubletten.shape[0]\n",
    "c = df_dubletten.shape[0]\n",
    "b = df_dubl_einspielen.shape[0] #Auswahl der neuen Treffer\n",
    "m = df_in_aleph_nicht_einspielen.shape[0]\n",
    "n = df_ganz_neu.shape[0]\n",
    "h = df_neu_aleph_einspielen.shape[0]\n",
    "j = df_neu_nicht_einspielen.shape[0]\n",
    "o = df_in_aleph_update.shape[0]\n",
    "g = df_in_aleph.shape[0]\n",
    "k = df_alephIDs.shape[0]\n",
    "z = df_neu_aleph_einspielen.shape[0]       #neu ermitteln aus neuen\n",
    "l = df_aleph_loeschen.shape[0]\n",
    "y = df_dubl_nicht_einspielen.shape[0]\n",
    "\n",
    "\n",
    "print('Kleine Statistik:\\n=====================================',\n",
    "    '\\nGelieferte Datensätze:             ', x,\n",
    "    '\\n--------------------------------------------', \n",
    "    '\\nSätze ohne Dubletten               ', a,\n",
    "    '\\n   Dubletten:              ', c,\n",
    "    '\\n   Auswahl zum Einspielen  ', b,\n",
    "    '\\n   in Aleph löschen        ', y,\n",
    "    '\\nZu prüfende Datensätze:            ', a+b,\n",
    "    '\\n--------------------------------------------', \n",
    "    '\\nPrüfung Titel in Aleph:            ', g,\n",
    "    '\\n   Davon als Update        ', o,\n",
    "    '\\n   Davon in Aleph löschen  ', m ,    \n",
    "    '\\nPrüfung neue Titel    :            ', n,\n",
    "    '\\n   Davon ganz neu          ', h,\n",
    "    '\\n   Davon bereits Bestand   ', j,      \n",
    "    '\\n--------------------------------------------', \n",
    "    '\\nTitel, die in Aleph verarbeitet werden: ', o+h,\n",
    "    '\\n--------------------------------------------', \n",
    "    '\\nDatensätze GES02 vor Einspielen:   ', k,\n",
    "    '\\nNicht mehr im Export               -', l,\n",
    "    '\\nTitel in Aleph löschen, da Bestand -', m,\n",
    "    '\\nZu löschen, da Dublette            -', y,\n",
    "    '\\nNeue Titel für Aleph               +', h,\n",
    "    '\\n--------------------------------------------', \n",
    "    '\\nIn Aleph nach Einspielen:          ', k-l-m-y+h,)\n",
    "\n",
    "#hier entsprechende Einträge für die Log-Datei\n",
    "\n",
    "with open ('./log/pda_import_log.txt', 'a') as log:\n",
    "    log.write(\"\\nGelieferte Datensätze:             \" + str(x))\n",
    "    log.write(\"\\n--------------------------------------------\\n\")\n",
    "    log.write(\"\\nSätze ohne Dubletten               \" + str(a))\n",
    "    log.write(\"\\n   Dubletten:              \" + str(c))\n",
    "    log.write(\"\\n   Davon in Aleph löeschen \" + str(y))\n",
    "    log.write(\"\\n   Auswahl zum Einspielen  \" + str(b))\n",
    "    log.write(\"\\nZu prüfende Datensätze:            \" + str(a+b))\n",
    "    log.write(\"\\n--------------------------------------------\\n\")\n",
    "    log.write(\"\\nPrüfung Titel in Aleph:            \" + str(g))\n",
    "    log.write(\"\\n   Davon als Update        \" + str(o))\n",
    "    log.write(\"\\n   Davon in Aleph löschen  \" + str(m) + \"    \\n\")   \n",
    "    log.write(\"\\nPrüfung neue Titel    :            \" + str(n))\n",
    "    log.write(\"\\n   Davon ganz neu          \" + str(h))\n",
    "    log.write(\"\\n   Davon bereits Bestand   \" + str(j) + \"    \\n\")     \n",
    "    log.write(\"\\n--------------------------------------------\\n\")\n",
    "    log.write(\"\\nTitel, die in Aleph verarbeitet werden: \" + str(o+h))\n",
    "    log.write(\"\\n--------------------------------------------\\n\")\n",
    "    log.write(\"\\nDatensätze GES02 vor Einspielen:   \" + str(k))\n",
    "    log.write(\"\\nNicht mehr im Export               -\" + str(l))\n",
    "    log.write(\"\\nZu löschender dubletter Titel      -\" + str(y))\n",
    "    log.write(\"\\nTitel in Aleph löschen, da Bestand -\" + str(m))\n",
    "    log.write(\"\\nNeue Titel für Aleph               +\" + str(h))\n",
    "    log.write(\"\\n--------------------------------------------\\n\")\n",
    "    log.write(\"\\nIn Aleph nach Einspielen:          \" + str(k-l-m-y+h))\n",
    "    log.write(\"\\n--------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## 4. Exportdateien Aufbereiten\n",
    "\n",
    "#### Zielformat für das Einspielen in Aleph:\n",
    "\n",
    "    000000001 LDR   L -----nM2.01200024------h              \n",
    "    000000001 020   L $$a (object_id))\n",
    "    000000001 030   L $$aaz||rrrza||||\n",
    "    000000001 051   L $$am|||||||\n",
    "    000000001 070   L $$aSchweitzer\n",
    "    000000001 077   L $$aMonographie\n",
    "    000000001 078   L $$aSchweitzer\n",
    "    000000001 082   L $$azum Bestellen\n",
    "    000000001 100   L $$a (contributor_1)\n",
    "    000000001 104   L $$a (contributor_2)\n",
    "    000000001 108   L $$a (contributor_3)\n",
    "    000000001 331   L $$a (title_sep)\n",
    "    000000001 335   L $$a (subtitle_all)\n",
    "    000000001 403   L $$a (edition_number / edition_text)  #noch prüfen, was besser zu verwenden ist \n",
    "    000000001 419   L $$b (publisher) $$a (date_combined)\n",
    "    000000001 433   L $$a (pages)\n",
    "    000000001 451   L $$a (series)\n",
    "    000000001 520   L $$a (thesis)\n",
    "    000000001 540   L $$a (isbn_ean)\n",
    "    000000001 656   L $$a (cover)\n",
    "    000000001 750   L $$a (description)\n",
    "    000000001 655   L $$zOrder me$$umailto:bib@mpifg.de?subject=Bestellwunsch        \n",
    "    \n",
    "Anmerkung zum Feld 655: die URL wird NACH dem Einspielen in Aleph mit der Datensatz-ID angereichert (siehe Juypter-Notebook \"Link-Anreicherung\"), um einen klaren Bestellink für den Kaufvorschlag zu haben\n",
    "\n",
    "*Hierfür werden immer die Feldbenennung und bestimmte Codierungen VOR den Inhalt - in Klammern de Bezeichnung der entsprechenden Spalte - gesetzt, bzw. erfoderliche Felder komplett neu hinzugefügt.   \n",
    "Am Anfang jeder Zeile braucht Aleph eine 9-Stellige eindeutige Zahl pro Titel.*   \n",
    "\n",
    "*Manchmal ließ sich der Inhalt einer Spalte direkt in die Datei schreiben, manchmal musst die Spalte zuvor über apply aufbereitet werden.* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Aufbereiten der neuen Titel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aleph_einspielen = df_neu_aleph_einspielen           #zur vereinfachten Wiederverwertung des alten Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aleph_einspielen[\"020\"] = df_aleph_einspielen[\"object_id\"].apply(lambda x: f\"020   L $$a{x}\") \n",
    "del df_aleph_einspielen[\"object_id\"]                                                                      #um das df nicht unnötig anwachsen zu lassen, jeweils alte Spalte löschen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Besondere Aufbereitung der Personendaten\n",
    "\n",
    "*Da bis zu 3 Personen in einer Spalte zu finden sind, werden diese im Discovery nicht getrennt suchbar, darum werden sie gesplittet. Für die Dublettenkontrolle hat sich das als irrelevant erwiesen, darum erfolgt dieser Schritt erst hier.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "person = df_aleph_einspielen[\"contributor\"].str.split(';', expand=True)                         #Für saubere Daten, die Autorenangabe splitten und in getrennte Felder schreiben\n",
    "\n",
    "df_aleph_einspielen[\"contributor_1\"]= person[0]\n",
    "df_aleph_einspielen[\"contributor_2\"]= person[1]\n",
    "df_aleph_einspielen[\"contributor_3\"]= person[2]\n",
    "\n",
    "df_aleph_einspielen[\"contributor_1\"]= df_aleph_einspielen[\"contributor_1\"].replace(np.nan, '', regex=True)\n",
    "df_aleph_einspielen[\"contributor_2\"]= df_aleph_einspielen[\"contributor_2\"].replace(np.nan, '', regex=True)\n",
    "df_aleph_einspielen[\"contributor_3\"]= df_aleph_einspielen[\"contributor_3\"].replace(np.nan, '', regex=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Besondere Aufbereitung des Erscheinungsdatum und Erscheinungsjahres\n",
    "\n",
    "*In der Auswahl unserer Titel befinden sich auch im Erscheinen befindliche Titel der kommenden Monate. Diese Information möchten wir gerne im Discovery sichtbar machen. Hierfür bleibt uns nur Aleph-Feld 419c, das dem Erscheinungsjahr vorbehalten ist.   \n",
    "Wunsch ist es: Wenn des Erscheinungsdatum weiter als 10 Tage weg vom heutigen Datum ist, soll das komplette Datum angezeigt werden, ansonsten nur das Erscheinungsjahr.*\n",
    "\n",
    "Zur Umsetzung muss die Spalte \"publication_date\" in ein Datum verwandelt werden und nach den genannten Kriterien unterschiedlich angezeigt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "today = int(time.strftime('%Y%m%d'))\n",
    "df_aleph_einspielen[\"coming_soon\"] = np.where(df_aleph_einspielen[\"publication_date\"].astype(int) > today+10, df_aleph_einspielen[\"publication_date\"], np.nan) #zieht die über 10 Tage raus, brauchen nan für Umwandlung in Datum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aleph_einspielen[\"publication_date_soon\"] = df_aleph_einspielen[\"coming_soon\"].astype(str).str.replace('00','01')\n",
    "#df_aleph_einspielen[\"publication_date_soon\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aleph_einspielen[\"year\"] = df_aleph_einspielen[\"publication_date_soon\"].astype(str).str.slice(start=0,stop=4)    #einfaches Zerlegen in die Datumsbestandteile und anschließendes Zusammenfügen\n",
    "df_aleph_einspielen[\"month\"] = df_aleph_einspielen[\"publication_date_soon\"].astype(str).str.slice(start=4,stop=6)\n",
    "df_aleph_einspielen[\"day\"] = df_aleph_einspielen[\"publication_date_soon\"].astype(str).str.slice(start=6,stop=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aleph_einspielen[\"full_coming_soon\"] = df_aleph_einspielen[\"year\"]+'-'+df_aleph_einspielen[\"month\"]+'-'+df_aleph_einspielen[\"day\"]\n",
    "df_aleph_einspielen[\"coming_soon\"] = df_aleph_einspielen[\"full_coming_soon\"].astype(str).str.replace('nan--','') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "420               \n",
       "647               \n",
       "649               \n",
       "717               \n",
       "723     2022-09-21\n",
       "           ...    \n",
       "1195    2022-10-20\n",
       "1197    2022-10-20\n",
       "1201              \n",
       "1203    2022-09-23\n",
       "1204    2022-10-20\n",
       "Name: coming_soon, Length: 390, dtype: object"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_aleph_einspielen[\"coming_soon\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "420           2022\n",
       "647           2022\n",
       "649           2018\n",
       "717           2022\n",
       "723     2022-09-21\n",
       "           ...    \n",
       "1195    2022-10-20\n",
       "1197    2022-10-20\n",
       "1201          2022\n",
       "1203    2022-09-23\n",
       "1204    2022-10-20\n",
       "Name: date_combined, Length: 390, dtype: object"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_aleph_einspielen[\"published\"] = np.where(df_aleph_einspielen[\"coming_soon\"] == '', df_aleph_einspielen[\"publication_year\"], '') #Auslesen und Kombinieren der Daten\n",
    "df_aleph_einspielen[\"year_publ\"] = df_aleph_einspielen[\"published\"].astype(str).str.slice(start=0,stop=4)                          #da wieder .0 am Ende war, Jahreszahl ausschneidens\n",
    "df_aleph_einspielen[\"date_combined\"] = df_aleph_einspielen[\"year_publ\"]+df_aleph_einspielen[\"coming_soon\"]\n",
    "df_aleph_einspielen['date_combined']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_aleph_einspielen.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "420     9780192859501\n",
       "647     9783837624878\n",
       "649     9783110544671\n",
       "717     9783110718324\n",
       "723     9783423531399\n",
       "            ...      \n",
       "1195    9780745346854\n",
       "1197    9781839109584\n",
       "1201    9781009224536\n",
       "1203    9780520374010\n",
       "1204    9780870712180\n",
       "Name: isbn_ean, Length: 390, dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_aleph_einspielen['isbn_ean'] = df_aleph_einspielen['isbn_ean'].astype(np.int64)   #da die Zahl als Object genommen wurde, bekam sie ein .0 angehängt, das ist durch umwandeln in Zahl weg\n",
    "\n",
    "df_aleph_einspielen['isbn_ean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aleph_einspielen[\"419b\"] = df_aleph_einspielen[\"publisher\"].apply(lambda x: f\"419   L $$b{x}\") \n",
    "df_aleph_einspielen[\"419c\"] = df_aleph_einspielen[\"date_combined\"].apply(lambda x: f\"$$c{x}\")                  \n",
    "\n",
    "df_aleph_einspielen[\"419\"] = df_aleph_einspielen[\"419b\"]+df_aleph_einspielen[\"419c\"]                           #Für die Korrekte Eingabe brauche ich Verlag und Jahr in einer Spalte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aleph_einspielen[\"403\"] = df_aleph_einspielen[\"edition_text\"].apply(lambda x: f\"403   L $$a{x}\") \n",
    "df_aleph_einspielen[\"433\"] = df_aleph_einspielen[\"pages\"].apply(lambda x: f\"433   L $$b{x}\")\n",
    "df_aleph_einspielen[\"451\"] = df_aleph_einspielen[\"series\"].apply(lambda x: f\"451   L $$b{x}\") \n",
    "df_aleph_einspielen[\"520\"] = df_aleph_einspielen[\"thesis\"].apply(lambda x: f\"520   L $$a{x}\") \n",
    "df_aleph_einspielen[\"540\"] = df_aleph_einspielen[\"isbn_ean\"].apply(lambda x: f\"540   L $$a{x}\") \n",
    "df_aleph_einspielen[\"656\"] = df_aleph_einspielen[\"cover\"].apply(lambda x: f\"656   L $$u{x}\") \n",
    "df_aleph_einspielen[\"750\"] = df_aleph_einspielen[\"description\"].apply(lambda x: f\"750   L $$a{x}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Für das Durchzählen der Titel braucht es eine neue Spalte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hier entsteht eine neue Spalte mit Zahlen ab 1 durchgehend gezählt, die für den korrekten Import der Daten in Aleph nötig ist\n",
    "x = df_aleph_einspielen.shape[0]   \n",
    "df_aleph_einspielen[\"id\"] = range(1,x+1)                                                       #Notwendig ist die Zählung ab 1, da Aleph sonst nicht korrekt einließt\n",
    "df_aleph_einspielen[\"id\"] = df_aleph_einspielen[\"id\"].apply(lambda x: f\"{x:09d}\")              #Die Zahl muss 9-Stellig aufgefüllt werden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#### Vorbereitungen abgeschlossen, jetzt das Schreiben der Datei im Aleph-Sequential-Format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"./output/ges02_neu\", \"w\", encoding=\"utf-8\") as fa:  #durch das Encoding hier, kommen Sonderzeichen richtig rüber\n",
    "    for i in df_aleph_einspielen.index:\n",
    "        fa.write(df_aleph_einspielen[\"id\"][i]+' LDR   L -----nM2.01200024------h'+'\\n')\n",
    "        fa.write(df_aleph_einspielen[\"id\"][i]+' '+df_aleph_einspielen[\"020\"][i]+'\\n')\n",
    "        fa.write(df_aleph_einspielen[\"id\"][i]+' 030   L $$aaz||rrrza||||'+'\\n')\n",
    "        fa.write(df_aleph_einspielen[\"id\"][i]+' 051   L $$am|||||||m|||||||'+'\\n')\n",
    "        fa.write(df_aleph_einspielen[\"id\"][i]+' 077   L $$aMonographie'+'\\n')\n",
    "        fa.write(df_aleph_einspielen[\"id\"][i]+' 078   L $$aSchweitzer'+'\\n')\n",
    "        fa.write(df_aleph_einspielen[\"id\"][i]+' 082   L $$azum Bestellen'+'\\n')\n",
    "        fa.write(df_aleph_einspielen[\"id\"][i]+' 100   L $$a'+df_aleph_einspielen[\"contributor_1\"][i]+'\\n')\n",
    "        fa.write(df_aleph_einspielen[\"id\"][i]+' 104   L $$a'+df_aleph_einspielen[\"contributor_2\"][i]+'\\n')\n",
    "        fa.write(df_aleph_einspielen[\"id\"][i]+' 108   L $$a'+df_aleph_einspielen[\"contributor_3\"][i]+'\\n')\n",
    "        fa.write(df_aleph_einspielen[\"id\"][i]+' 331   L $$a'+df_aleph_einspielen[\"title_sep\"][i]+'\\n')\n",
    "        fa.write(df_aleph_einspielen[\"id\"][i]+' 335   L $$a'+df_aleph_einspielen[\"subtitle_all\"][i]+'\\n')\n",
    "        fa.write(df_aleph_einspielen[\"id\"][i]+' '+df_aleph_einspielen[\"403\"][i]+'\\n')\n",
    "        fa.write(df_aleph_einspielen[\"id\"][i]+' '+df_aleph_einspielen[\"419\"][i]+'\\n')\n",
    "        fa.write(df_aleph_einspielen[\"id\"][i]+' '+df_aleph_einspielen[\"433\"][i]+'\\n')\n",
    "        fa.write(df_aleph_einspielen[\"id\"][i]+' '+df_aleph_einspielen[\"451\"][i]+'\\n')\n",
    "        fa.write(df_aleph_einspielen[\"id\"][i]+' '+df_aleph_einspielen[\"520\"][i]+'\\n')\n",
    "        fa.write(df_aleph_einspielen[\"id\"][i]+' '+df_aleph_einspielen[\"540\"][i]+'\\n')\n",
    "        fa.write(df_aleph_einspielen[\"id\"][i]+' 655   L $$zOrder me$$umailto:bib@mpifg.de?subject=Bestellwunsch'+'\\n')\n",
    "        fa.write(df_aleph_einspielen[\"id\"][i]+' '+df_aleph_einspielen[\"656\"][i]+'$$3Cover\\n')\n",
    "        fa.write(df_aleph_einspielen[\"id\"][i]+' '+df_aleph_einspielen[\"750\"][i]+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### 2. Daten für Update\n",
    "\n",
    "*es wird anhand der Spalte \"last_modified\" geprüft, ob die Titel seit dem letzten Einspielen ein Update erfahren haben*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Um die Menge zum Updaten zu reduzieren, werden nur die rausgezogen, die tatsächlich ein Aktualisierungsdatum haben"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-24 10:49:07.805921\n"
     ]
    }
   ],
   "source": [
    "tday = datetime.datetime.now()\n",
    "td = datetime.timedelta(days = 7)\n",
    "u = tday - td\n",
    "df_in_aleph_update['timespan'] = u                                                           # Einfügen einer Spalte mit Datum vor 10 Tagen als Basis für Abfrage zu Update-Notwendigkeit\n",
    "print(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       2022-08-30 18:31:12\n",
       "1       2022-08-19 17:16:55\n",
       "2       2022-08-30 19:05:12\n",
       "3       2022-08-17 17:22:37\n",
       "4       2022-08-28 18:03:17\n",
       "                ...        \n",
       "14805   2022-08-25 17:59:00\n",
       "14806   2022-08-15 17:22:15\n",
       "14807   2022-08-05 18:35:35\n",
       "14808   2022-08-15 17:26:47\n",
       "14809   2022-08-03 01:18:21\n",
       "Name: last_modified, Length: 14789, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_in_aleph_update['last_modified'] = pd.to_datetime(df_in_aleph_update.last_modified)          #Umwandlung, da Spalteninhalt object ist\n",
    "df_in_aleph_update['last_modified']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       2022-08-30 18:31:12\n",
       "1                       NaT\n",
       "2       2022-08-30 19:05:12\n",
       "3                       NaT\n",
       "4       2022-08-28 18:03:17\n",
       "                ...        \n",
       "14805   2022-08-25 17:59:00\n",
       "14806                   NaT\n",
       "14807                   NaT\n",
       "14808                   NaT\n",
       "14809                   NaT\n",
       "Name: true, Length: 14789, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_in_aleph_update['true'] = np.where(df_in_aleph_update['last_modified'] > u, df_in_aleph_update['last_modified'], np.datetime64('NaT'))\n",
    "df_in_aleph_update['true']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_in_aleph_update_true = df_in_aleph_update[pd.notnull(df_in_aleph_update['true'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_0</th>\n",
       "      <th>index</th>\n",
       "      <th>object_id</th>\n",
       "      <th>isbn_ean</th>\n",
       "      <th>title</th>\n",
       "      <th>subtitle</th>\n",
       "      <th>contributor</th>\n",
       "      <th>publisher</th>\n",
       "      <th>series</th>\n",
       "      <th>thesis</th>\n",
       "      <th>...</th>\n",
       "      <th>subtitle_comparison</th>\n",
       "      <th>subtitle_comparison2</th>\n",
       "      <th>subtitle_all</th>\n",
       "      <th>short_title</th>\n",
       "      <th>url_ges</th>\n",
       "      <th>url_ebx</th>\n",
       "      <th>Abfrage_ges</th>\n",
       "      <th>Abfrage_ebx</th>\n",
       "      <th>timespan</th>\n",
       "      <th>true</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>160055285</td>\n",
       "      <td>9783404070022</td>\n",
       "      <td>Fake Facts</td>\n",
       "      <td>Wie Verschwörungstheorien unser Denken bestimmen</td>\n",
       "      <td>Katharina Nocun;Pia Lamberty</td>\n",
       "      <td>Quadriga</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>Wie Verschwörungstheorien unser Denken bestimmen</td>\n",
       "      <td></td>\n",
       "      <td>Wie Verschwörungstheorien unser Denken bestimmen</td>\n",
       "      <td>Fake Facts Wie Verschwörungstheorien unser Den...</td>\n",
       "      <td>http://aleph.mpg.de/X?op=find&amp;base=ges01&amp;reque...</td>\n",
       "      <td>http://aleph.mpg.de/X?op=find&amp;base=ebx01&amp;reque...</td>\n",
       "      <td>neu</td>\n",
       "      <td>neu</td>\n",
       "      <td>2022-08-24 10:49:07.805921</td>\n",
       "      <td>2022-08-30 18:31:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>161274400</td>\n",
       "      <td>9783949098031</td>\n",
       "      <td>Der Preis der Zukunft</td>\n",
       "      <td>Warum Deflation der Schlüssel zum Wohlstand vo...</td>\n",
       "      <td>Jeff Booth</td>\n",
       "      <td>Aprycot Media</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>Warum Deflation der Schlüssel zum Wohlstand vo...</td>\n",
       "      <td></td>\n",
       "      <td>Warum Deflation der Schlüssel zum Wohlstand vo...</td>\n",
       "      <td>Der Preis der Zukunft Warum Deflation der Schl...</td>\n",
       "      <td>http://aleph.mpg.de/X?op=find&amp;base=ges01&amp;reque...</td>\n",
       "      <td>http://aleph.mpg.de/X?op=find&amp;base=ebx01&amp;reque...</td>\n",
       "      <td>neu</td>\n",
       "      <td>neu</td>\n",
       "      <td>2022-08-24 10:49:07.805921</td>\n",
       "      <td>2022-08-30 19:05:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>156899389</td>\n",
       "      <td>9781529110630</td>\n",
       "      <td>Another Now</td>\n",
       "      <td>Dispatches from an Alternative Present from th...</td>\n",
       "      <td>Yanis Varoufakis</td>\n",
       "      <td>Vintage</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>Dispatches from an Alternative Present from th...</td>\n",
       "      <td></td>\n",
       "      <td>Dispatches from an Alternative Present from th...</td>\n",
       "      <td>Another Now Dispatches from an Alternative Pre...</td>\n",
       "      <td>http://aleph.mpg.de/X?op=find&amp;base=ges01&amp;reque...</td>\n",
       "      <td>http://aleph.mpg.de/X?op=find&amp;base=ebx01&amp;reque...</td>\n",
       "      <td>neu</td>\n",
       "      <td>neu</td>\n",
       "      <td>2022-08-24 10:49:07.805921</td>\n",
       "      <td>2022-08-28 18:03:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>32</td>\n",
       "      <td>58</td>\n",
       "      <td>161154394</td>\n",
       "      <td>9781433191077</td>\n",
       "      <td>Opening Pathways, Building Bridges</td>\n",
       "      <td>Skilled Migration of Mexican Scientists and En...</td>\n",
       "      <td>Tonatiuh Anzures</td>\n",
       "      <td>Peter Lang Verlag</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>Skilled Migration of Mexican Scientists and En...</td>\n",
       "      <td></td>\n",
       "      <td>Skilled Migration of Mexican Scientists and En...</td>\n",
       "      <td>Opening Pathways, Building Bridges Skilled Mig...</td>\n",
       "      <td>http://aleph.mpg.de/X?op=find&amp;base=ges01&amp;reque...</td>\n",
       "      <td>http://aleph.mpg.de/X?op=find&amp;base=ebx01&amp;reque...</td>\n",
       "      <td>neu</td>\n",
       "      <td>neu</td>\n",
       "      <td>2022-08-24 10:49:07.805921</td>\n",
       "      <td>2022-08-25 17:56:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>33</td>\n",
       "      <td>59</td>\n",
       "      <td>161256641</td>\n",
       "      <td>9781527570283</td>\n",
       "      <td>Digitalization in Organizations</td>\n",
       "      <td></td>\n",
       "      <td>Mehmed Zahid Coegenli</td>\n",
       "      <td>Cambridge Scholars Publishing</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Digitalization in Organizations  / Mehmed Zahi...</td>\n",
       "      <td>http://aleph.mpg.de/X?op=find&amp;base=ges01&amp;reque...</td>\n",
       "      <td>http://aleph.mpg.de/X?op=find&amp;base=ebx01&amp;reque...</td>\n",
       "      <td>neu</td>\n",
       "      <td>neu</td>\n",
       "      <td>2022-08-24 10:49:07.805921</td>\n",
       "      <td>2022-08-25 01:16:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14792</th>\n",
       "      <td>15997</td>\n",
       "      <td>14955</td>\n",
       "      <td>164805381</td>\n",
       "      <td>9780520363663</td>\n",
       "      <td>A Flora of Southern California</td>\n",
       "      <td></td>\n",
       "      <td>Philip A. Munz</td>\n",
       "      <td>University of California Press</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>A Flora of Southern California  / Philip A. Munz</td>\n",
       "      <td>http://aleph.mpg.de/X?op=find&amp;base=ges01&amp;reque...</td>\n",
       "      <td>http://aleph.mpg.de/X?op=find&amp;base=ebx01&amp;reque...</td>\n",
       "      <td>neu</td>\n",
       "      <td>neu</td>\n",
       "      <td>2022-08-24 10:49:07.805921</td>\n",
       "      <td>2022-08-28 17:25:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14793</th>\n",
       "      <td>15998</td>\n",
       "      <td>6794</td>\n",
       "      <td>159856452</td>\n",
       "      <td>9780520382527</td>\n",
       "      <td>A Field Guide to White Supremacy</td>\n",
       "      <td></td>\n",
       "      <td>Kathleen Belew</td>\n",
       "      <td>University of California Press</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>A Field Guide to White Supremacy  / Kathleen B...</td>\n",
       "      <td>http://aleph.mpg.de/X?op=find&amp;base=ges01&amp;reque...</td>\n",
       "      <td>http://aleph.mpg.de/X?op=find&amp;base=ebx01&amp;reque...</td>\n",
       "      <td>neu</td>\n",
       "      <td>neu</td>\n",
       "      <td>2022-08-24 10:49:07.805921</td>\n",
       "      <td>2022-08-28 17:25:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14794</th>\n",
       "      <td>15999</td>\n",
       "      <td>3734</td>\n",
       "      <td>160093944</td>\n",
       "      <td>9781350095977</td>\n",
       "      <td>A Feminist Mythology</td>\n",
       "      <td></td>\n",
       "      <td>Chiara Bottici</td>\n",
       "      <td>Bloomsbury Academic</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>A Feminist Mythology  / Chiara Bottici</td>\n",
       "      <td>http://aleph.mpg.de/X?op=find&amp;base=ges01&amp;reque...</td>\n",
       "      <td>http://aleph.mpg.de/X?op=find&amp;base=ebx01&amp;reque...</td>\n",
       "      <td>neu</td>\n",
       "      <td>neu</td>\n",
       "      <td>2022-08-24 10:49:07.805921</td>\n",
       "      <td>2022-08-28 17:45:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14798</th>\n",
       "      <td>16003</td>\n",
       "      <td>10270</td>\n",
       "      <td>162745199</td>\n",
       "      <td>9781350026971</td>\n",
       "      <td>A Cultural History of Shopping</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Bloomsbury Academic</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>A Cultural History of Shopping  /</td>\n",
       "      <td>http://aleph.mpg.de/X?op=find&amp;base=ges01&amp;reque...</td>\n",
       "      <td>http://aleph.mpg.de/X?op=find&amp;base=ebx01&amp;reque...</td>\n",
       "      <td>neu</td>\n",
       "      <td>neu</td>\n",
       "      <td>2022-08-24 10:49:07.805921</td>\n",
       "      <td>2022-08-26 02:48:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14805</th>\n",
       "      <td>16011</td>\n",
       "      <td>10521</td>\n",
       "      <td>162111474</td>\n",
       "      <td>9781474494953</td>\n",
       "      <td>A Call to Dissent</td>\n",
       "      <td>Defending Democracy Against Extremism and Popu...</td>\n",
       "      <td>Stuart Sim</td>\n",
       "      <td>Edinburgh University Press</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>Defending Democracy Against Extremism and Popu...</td>\n",
       "      <td></td>\n",
       "      <td>Defending Democracy Against Extremism and Popu...</td>\n",
       "      <td>A Call to Dissent Defending Democracy Against ...</td>\n",
       "      <td>http://aleph.mpg.de/X?op=find&amp;base=ges01&amp;reque...</td>\n",
       "      <td>http://aleph.mpg.de/X?op=find&amp;base=ebx01&amp;reque...</td>\n",
       "      <td>neu</td>\n",
       "      <td>neu</td>\n",
       "      <td>2022-08-24 10:49:07.805921</td>\n",
       "      <td>2022-08-25 17:59:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5612 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       level_0  index  object_id       isbn_ean  \\\n",
       "0            0      0  160055285  9783404070022   \n",
       "2            2      7  161274400  9783949098031   \n",
       "4            5     10  156899389  9781529110630   \n",
       "22          32     58  161154394  9781433191077   \n",
       "23          33     59  161256641  9781527570283   \n",
       "...        ...    ...        ...            ...   \n",
       "14792    15997  14955  164805381  9780520363663   \n",
       "14793    15998   6794  159856452  9780520382527   \n",
       "14794    15999   3734  160093944  9781350095977   \n",
       "14798    16003  10270  162745199  9781350026971   \n",
       "14805    16011  10521  162111474  9781474494953   \n",
       "\n",
       "                                    title  \\\n",
       "0                              Fake Facts   \n",
       "2                   Der Preis der Zukunft   \n",
       "4                             Another Now   \n",
       "22     Opening Pathways, Building Bridges   \n",
       "23        Digitalization in Organizations   \n",
       "...                                   ...   \n",
       "14792      A Flora of Southern California   \n",
       "14793    A Field Guide to White Supremacy   \n",
       "14794                A Feminist Mythology   \n",
       "14798      A Cultural History of Shopping   \n",
       "14805                   A Call to Dissent   \n",
       "\n",
       "                                                subtitle  \\\n",
       "0       Wie Verschwörungstheorien unser Denken bestimmen   \n",
       "2      Warum Deflation der Schlüssel zum Wohlstand vo...   \n",
       "4      Dispatches from an Alternative Present from th...   \n",
       "22     Skilled Migration of Mexican Scientists and En...   \n",
       "23                                                         \n",
       "...                                                  ...   \n",
       "14792                                                      \n",
       "14793                                                      \n",
       "14794                                                      \n",
       "14798                                                      \n",
       "14805  Defending Democracy Against Extremism and Popu...   \n",
       "\n",
       "                        contributor                       publisher series  \\\n",
       "0      Katharina Nocun;Pia Lamberty                        Quadriga          \n",
       "2                        Jeff Booth                   Aprycot Media          \n",
       "4                  Yanis Varoufakis                         Vintage          \n",
       "22                 Tonatiuh Anzures               Peter Lang Verlag          \n",
       "23            Mehmed Zahid Coegenli   Cambridge Scholars Publishing          \n",
       "...                             ...                             ...    ...   \n",
       "14792                Philip A. Munz  University of California Press          \n",
       "14793                Kathleen Belew  University of California Press          \n",
       "14794                Chiara Bottici             Bloomsbury Academic          \n",
       "14798                                           Bloomsbury Academic          \n",
       "14805                    Stuart Sim      Edinburgh University Press          \n",
       "\n",
       "      thesis  ...                                subtitle_comparison  \\\n",
       "0             ...   Wie Verschwörungstheorien unser Denken bestimmen   \n",
       "2             ...  Warum Deflation der Schlüssel zum Wohlstand vo...   \n",
       "4             ...  Dispatches from an Alternative Present from th...   \n",
       "22            ...  Skilled Migration of Mexican Scientists and En...   \n",
       "23            ...                                                      \n",
       "...      ...  ...                                                ...   \n",
       "14792         ...                                                      \n",
       "14793         ...                                                      \n",
       "14794         ...                                                      \n",
       "14798         ...                                                      \n",
       "14805         ...  Defending Democracy Against Extremism and Popu...   \n",
       "\n",
       "      subtitle_comparison2                                       subtitle_all  \\\n",
       "0                            Wie Verschwörungstheorien unser Denken bestimmen   \n",
       "2                           Warum Deflation der Schlüssel zum Wohlstand vo...   \n",
       "4                           Dispatches from an Alternative Present from th...   \n",
       "22                          Skilled Migration of Mexican Scientists and En...   \n",
       "23                                                                              \n",
       "...                    ...                                                ...   \n",
       "14792                                                                           \n",
       "14793                                                                           \n",
       "14794                                                                           \n",
       "14798                                                                           \n",
       "14805                       Defending Democracy Against Extremism and Popu...   \n",
       "\n",
       "                                             short_title  \\\n",
       "0      Fake Facts Wie Verschwörungstheorien unser Den...   \n",
       "2      Der Preis der Zukunft Warum Deflation der Schl...   \n",
       "4      Another Now Dispatches from an Alternative Pre...   \n",
       "22     Opening Pathways, Building Bridges Skilled Mig...   \n",
       "23     Digitalization in Organizations  / Mehmed Zahi...   \n",
       "...                                                  ...   \n",
       "14792   A Flora of Southern California  / Philip A. Munz   \n",
       "14793  A Field Guide to White Supremacy  / Kathleen B...   \n",
       "14794             A Feminist Mythology  / Chiara Bottici   \n",
       "14798                 A Cultural History of Shopping  /    \n",
       "14805  A Call to Dissent Defending Democracy Against ...   \n",
       "\n",
       "                                                 url_ges  \\\n",
       "0      http://aleph.mpg.de/X?op=find&base=ges01&reque...   \n",
       "2      http://aleph.mpg.de/X?op=find&base=ges01&reque...   \n",
       "4      http://aleph.mpg.de/X?op=find&base=ges01&reque...   \n",
       "22     http://aleph.mpg.de/X?op=find&base=ges01&reque...   \n",
       "23     http://aleph.mpg.de/X?op=find&base=ges01&reque...   \n",
       "...                                                  ...   \n",
       "14792  http://aleph.mpg.de/X?op=find&base=ges01&reque...   \n",
       "14793  http://aleph.mpg.de/X?op=find&base=ges01&reque...   \n",
       "14794  http://aleph.mpg.de/X?op=find&base=ges01&reque...   \n",
       "14798  http://aleph.mpg.de/X?op=find&base=ges01&reque...   \n",
       "14805  http://aleph.mpg.de/X?op=find&base=ges01&reque...   \n",
       "\n",
       "                                                 url_ebx Abfrage_ges  \\\n",
       "0      http://aleph.mpg.de/X?op=find&base=ebx01&reque...         neu   \n",
       "2      http://aleph.mpg.de/X?op=find&base=ebx01&reque...         neu   \n",
       "4      http://aleph.mpg.de/X?op=find&base=ebx01&reque...         neu   \n",
       "22     http://aleph.mpg.de/X?op=find&base=ebx01&reque...         neu   \n",
       "23     http://aleph.mpg.de/X?op=find&base=ebx01&reque...         neu   \n",
       "...                                                  ...         ...   \n",
       "14792  http://aleph.mpg.de/X?op=find&base=ebx01&reque...         neu   \n",
       "14793  http://aleph.mpg.de/X?op=find&base=ebx01&reque...         neu   \n",
       "14794  http://aleph.mpg.de/X?op=find&base=ebx01&reque...         neu   \n",
       "14798  http://aleph.mpg.de/X?op=find&base=ebx01&reque...         neu   \n",
       "14805  http://aleph.mpg.de/X?op=find&base=ebx01&reque...         neu   \n",
       "\n",
       "      Abfrage_ebx                   timespan                true  \n",
       "0             neu 2022-08-24 10:49:07.805921 2022-08-30 18:31:12  \n",
       "2             neu 2022-08-24 10:49:07.805921 2022-08-30 19:05:12  \n",
       "4             neu 2022-08-24 10:49:07.805921 2022-08-28 18:03:17  \n",
       "22            neu 2022-08-24 10:49:07.805921 2022-08-25 17:56:04  \n",
       "23            neu 2022-08-24 10:49:07.805921 2022-08-25 01:16:14  \n",
       "...           ...                        ...                 ...  \n",
       "14792         neu 2022-08-24 10:49:07.805921 2022-08-28 17:25:08  \n",
       "14793         neu 2022-08-24 10:49:07.805921 2022-08-28 17:25:18  \n",
       "14794         neu 2022-08-24 10:49:07.805921 2022-08-28 17:45:57  \n",
       "14798         neu 2022-08-24 10:49:07.805921 2022-08-26 02:48:06  \n",
       "14805         neu 2022-08-24 10:49:07.805921 2022-08-25 17:59:00  \n",
       "\n",
       "[5612 rows x 42 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_in_aleph_update_true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Erstellen der Update-Export-Datei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Zwischenschritt, um für alle in Aleph das Update zu starten\n",
    "#df_in_aleph_update_true = df_in_aleph_update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_in_aleph_update_true[\"020\"] = df_in_aleph_update_true[\"object_id\"].apply(lambda x: f\"020   L $$a{x}\") \n",
    "del df_in_aleph_update_true[\"object_id\"]                                                                      #um das df nicht unnötig anwachsen zu lassen, jeweils alte Spalte löschen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aufbereitung Personendaten\n",
    "\n",
    "person = df_in_aleph_update_true[\"contributor\"].str.split(';', expand=True)                         #Für saubere Daten, die Autorenangabe splitten und in getrennte Felder schreiben\n",
    "\n",
    "df_in_aleph_update_true[\"contributor_1\"]= person[0]\n",
    "df_in_aleph_update_true[\"contributor_2\"]= person[1]\n",
    "df_in_aleph_update_true[\"contributor_3\"]= person[2]\n",
    "\n",
    "df_in_aleph_update_true[\"contributor_1\"]= df_in_aleph_update_true[\"contributor_1\"].replace(np.nan, '', regex=True)\n",
    "df_in_aleph_update_true[\"contributor_2\"]= df_in_aleph_update_true[\"contributor_2\"].replace(np.nan, '', regex=True)\n",
    "df_in_aleph_update_true[\"contributor_3\"]= df_in_aleph_update_true[\"contributor_3\"].replace(np.nan, '', regex=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neue Schritte zur Aufbereitung des Erscheinungsdatums, da der Code von oben hier nicht ging - warum auch immer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#today = int(time.strftime('%Y%m%d'))\n",
    "#soon = today+10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_in_aleph_update_true['publ_date_repl'] = df_in_aleph_update_true['publication_date'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        20210827\n",
       "2        20210800\n",
       "4        20210909\n",
       "22       20210715\n",
       "23       20210727\n",
       "           ...   \n",
       "14792    20220819\n",
       "14793    20211026\n",
       "14794    20211021\n",
       "14798    20220519\n",
       "14805    20220501\n",
       "Name: publ_date_repl, Length: 5612, dtype: object"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_in_aleph_update_true['publ_date_repl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_in_aleph_update_true['publ_date_repl'] = df_in_aleph_update_true['publ_date_repl'].str.replace('00','01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20220801    216\n",
       "20220930    119\n",
       "20220901    103\n",
       "20220825     90\n",
       "20220429     88\n",
       "           ... \n",
       "20230202      1\n",
       "20210205      1\n",
       "20210126      1\n",
       "20220409      1\n",
       "              1\n",
       "Name: publ_date_repl, Length: 590, dtype: int64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_in_aleph_update_true['publ_date_repl'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       2021-08-27\n",
       "2       2021-08-01\n",
       "4       2021-09-09\n",
       "22      2021-07-15\n",
       "23      2021-07-27\n",
       "           ...    \n",
       "14792   2022-08-19\n",
       "14793   2021-10-26\n",
       "14794   2021-10-21\n",
       "14798   2022-05-19\n",
       "14805   2022-05-01\n",
       "Name: publ_date_repl_date, Length: 5612, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_in_aleph_update_true['publ_date_repl_date'] = pd.to_datetime(df_in_aleph_update_true['publ_date_repl'], errors='coerce')\n",
    "df_in_aleph_update_true['publ_date_repl_date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_in_aleph_update_true[\"coming_soon\"] = np.where(df_in_aleph_update_true[\"publ_date_repl_date\"] > u, df_in_aleph_update_true[\"publ_date_repl_date\"], np.datetime64('NaT'))  #df_in_aleph_update_true['today'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       NaT\n",
       "2       NaT\n",
       "4       NaT\n",
       "22      NaT\n",
       "23      NaT\n",
       "         ..\n",
       "14792   NaT\n",
       "14793   NaT\n",
       "14794   NaT\n",
       "14798   NaT\n",
       "14805   NaT\n",
       "Name: coming_soon, Length: 5612, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_in_aleph_update_true[\"coming_soon\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_in_aleph_update_true[\"coming_soon\"].replace('NaT','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        2021\n",
       "2        2021\n",
       "4        2021\n",
       "22       2021\n",
       "23       2021\n",
       "         ... \n",
       "14792    2022\n",
       "14793    2021\n",
       "14794    2021\n",
       "14798    2022\n",
       "14805    2022\n",
       "Name: date_combined, Length: 5612, dtype: object"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_in_aleph_update_true[\"date_combined\"] = np.where(df_in_aleph_update_true[\"coming_soon\"].astype(str) == 'NaT', df_in_aleph_update_true[\"publication_year\"], df_in_aleph_update_true[\"coming_soon\"].astype(str))\n",
    "df_in_aleph_update_true[\"date_combined\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        9783404070022\n",
       "2        9783949098031\n",
       "4        9781529110630\n",
       "22       9781433191077\n",
       "23       9781527570283\n",
       "             ...      \n",
       "14792    9780520363663\n",
       "14793    9780520382527\n",
       "14794    9781350095977\n",
       "14798    9781350026971\n",
       "14805    9781474494953\n",
       "Name: isbn_ean, Length: 5612, dtype: int64"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_in_aleph_update_true['isbn_ean'] = df_in_aleph_update_true['isbn_ean'].astype(np.int64)   #da die Zahl als Object genommen wurde, bekam sie ein .0 angehängt, das ist durch umwandeln in Zahl weg\n",
    "\n",
    "df_in_aleph_update_true['isbn_ean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bearbeitung der Felder\n",
    "\n",
    "df_in_aleph_update_true[\"419b\"] = df_in_aleph_update_true[\"publisher\"].apply(lambda x: f\"419   L $$b{x}\") \n",
    "df_in_aleph_update_true[\"419c\"] = df_in_aleph_update_true[\"date_combined\"].apply(lambda x: f\"$$c{x}\")                  \n",
    "\n",
    "df_in_aleph_update_true[\"419\"] = df_in_aleph_update_true[\"419b\"]+df_in_aleph_update_true[\"419c\"]                           #Für die Korrekte Eingabe brauche ich Verlag und Jahr in einer Spalte\n",
    "\n",
    "df_in_aleph_update_true[\"403\"] = df_in_aleph_update_true[\"edition_text\"].apply(lambda x: f\"403   L $$a{x}\") \n",
    "df_in_aleph_update_true[\"433\"] = df_in_aleph_update_true[\"pages\"].apply(lambda x: f\"433   L $$b{x}\")\n",
    "df_in_aleph_update_true[\"451\"] = df_in_aleph_update_true[\"series\"].apply(lambda x: f\"451   L $$b{x}\") \n",
    "df_in_aleph_update_true[\"520\"] = df_in_aleph_update_true[\"thesis\"].apply(lambda x: f\"520   L $$a{x}\") \n",
    "df_in_aleph_update_true[\"540\"] = df_in_aleph_update_true[\"isbn_ean\"].apply(lambda x: f\"540   L $$a{x}\") \n",
    "df_in_aleph_update_true[\"656\"] = df_in_aleph_update_true[\"cover\"].apply(lambda x: f\"656   L $$u{x}\") \n",
    "df_in_aleph_update_true[\"750\"] = df_in_aleph_update_true[\"description\"].apply(lambda x: f\"750   L $$a{x}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schreiben der Ausgabedatei, hier kleine Unterschiede zu den neuen Titeln. Vorhandene ids und bestimmte Felder können nicht verändert sein, brauchen also nicht übernommen zu werden.\n",
    "\n",
    "with open(\"./output/ges02_update\", \"w\", encoding=\"utf-8\") as fa:  #durch das Encoding hier, kommen Sonderzeichen richtig rüber\n",
    "    for i in df_in_aleph_update_true.index:\n",
    "        fa.write(df_in_aleph_update_true[\"ids\"][i]+' 100   L $$a'+df_in_aleph_update_true[\"contributor_1\"][i]+'\\n')\n",
    "        fa.write(df_in_aleph_update_true[\"ids\"][i]+' 104   L $$a'+df_in_aleph_update_true[\"contributor_2\"][i]+'\\n')\n",
    "        fa.write(df_in_aleph_update_true[\"ids\"][i]+' 108   L $$a'+df_in_aleph_update_true[\"contributor_3\"][i]+'\\n')\n",
    "        fa.write(df_in_aleph_update_true[\"ids\"][i]+' 331   L $$a'+df_in_aleph_update_true[\"title_sep\"][i]+'\\n')\n",
    "        fa.write(df_in_aleph_update_true[\"ids\"][i]+' 335   L $$a'+df_in_aleph_update_true[\"subtitle_all\"][i]+'\\n')\n",
    "        fa.write(df_in_aleph_update_true[\"ids\"][i]+' '+df_in_aleph_update_true[\"403\"][i]+'\\n')\n",
    "        fa.write(df_in_aleph_update_true[\"ids\"][i]+' '+df_in_aleph_update_true[\"419\"][i]+'\\n')\n",
    "        fa.write(df_in_aleph_update_true[\"ids\"][i]+' '+df_in_aleph_update_true[\"433\"][i]+'\\n')\n",
    "        fa.write(df_in_aleph_update_true[\"ids\"][i]+' '+df_in_aleph_update_true[\"451\"][i]+'\\n')\n",
    "        fa.write(df_in_aleph_update_true[\"ids\"][i]+' '+df_in_aleph_update_true[\"520\"][i]+'\\n')\n",
    "        fa.write(df_in_aleph_update_true[\"ids\"][i]+' '+df_in_aleph_update_true[\"540\"][i]+'\\n')\n",
    "        fa.write(df_in_aleph_update_true[\"ids\"][i]+' '+df_in_aleph_update_true[\"656\"][i]+'$$3Cover\\n')\n",
    "        fa.write(df_in_aleph_update_true[\"ids\"][i]+' '+df_in_aleph_update_true[\"750\"][i]+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abschließende Dinge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Abschließender Eintrag in Log-Datei\n",
    "endtime = time.strftime('%H:%M')\n",
    "\n",
    "with open ('./log/pda_import_log.txt', 'a') as log:                                                  # Da diese Log-Datei nicht unmittelbar gebraucht wird, hier fortlaufendes Schreiben in eine Datei\n",
    "    log.write('\\n                                     beendet ')\n",
    "    log.write(endtime)\n",
    "    log.write(\"\\n============================================================\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kopien bestimmter Daten zur Einsicht bzw. für Prüfzwecke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aleph_einspielen.to_csv('./output/Eingespielte_Titel_'+date+'.csv') \n",
    "df_in_aleph_update_true.to_csv('./output/Update_Titel_'+date+'.csv')\n",
    "\n",
    "df_in_aleph_nicht_einspielen.to_csv('./output/Aleph_loeschen_ebx_vorh_'+date+'.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "Folgende Schritte müssen mit den Dateien ausgeführt werden: \n",
    "\n",
    "\n",
    "1. Einspielen der Datei pda_ges01 als neue Titel in Aleph, hier dann auch Export der urls und Anreicherung mit der Aleph-ID mittels \"mailto_link_skript.ipynb\"\n",
    "2. Einspielen der DAtei pda_update als \"Änderungen bestehender Datensätze in Aleph\"\n",
    "3. Einspielen und löschen der Titel die in ges02_loeschen_1 und ges02_loeschen_2 vorhanden sind"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "metadata": {
   "interpreter": {
    "hash": "4fac973d8b48a5fcf37e7d133428a31fb47ebbd054f5d1feed8c0da486f2af46"
   }
  },
  "orig_nbformat": 2,
  "vscode": {
   "interpreter": {
    "hash": "84332f8093f13158109f003500ffea43e446781d3c3a4a2ba31125b2e300e715"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
